# Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ø±ØªÙ‚Ø§ÛŒ Ø±Ø¨Ø§Øª ØªØ³Øª ÙÛŒÚ†Ø± FSZ12-1.py

**ØªØ§Ø±ÛŒØ® Ø¨Ø±Ø±Ø³ÛŒ:** Û±Û¹ Ù†ÙˆØ§Ù…Ø¨Ø± Û²Û°Û²Ûµ  
**Ù†Ø³Ø®Ù‡ Ø±Ø¨Ø§Øª:** FSZ12-1.py  
**Ù‡Ø¯Ù:** ØªØ³Øª Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ø±Ø¨Ø§Øª ØªØ±ÛŒØ¯ÛŒÙ†Ú¯ ÙØ§Ø±Ú©Ø³  
**Ø§Ù‡Ù…ÛŒØª:** Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ - Ø§Ø´ØªØ¨Ø§Ù‡ Ø¯Ø± ØªØ³Øª = Ø¶Ø±Ø± Ù…Ø§Ù„ÛŒ Ø¯Ø± ØªØ±ÛŒØ¯ ÙˆØ§Ù‚Ø¹ÛŒ

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ

Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙÛŒÚ†Ø±Ù‡Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ ØªØ§ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±ÛŒØ¯ÛŒÙ†Ú¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´ÙˆÙ†Ø¯. Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ Ú©Ø¯ØŒ **Û²Û´ Ù…Ø´Ú©Ù„ Ø­ÛŒØ§ØªÛŒ Ùˆ Û±Û¸ Ù†Ù‚Ø·Ù‡ Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯** Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù†Ø¯ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ø§Ø¹Ø«:

1. âŒ **Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø´ØªØ¨Ø§Ù‡ ÙÛŒÚ†Ø±Ù‡Ø§** (ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ Ø¨Ù‡ Ø¬Ø§ÛŒ Ù‚ÙˆÛŒ)
2. âŒ **Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ´â€ŒØ¨ÛŒÙ†Ø§Ù†Ù‡** (Ø¨Ú©â€ŒØªØ³Øª Ø®ÙˆØ¨ØŒ ØªØ±ÛŒØ¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø¶Ø±Ø±)
3. âŒ **Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡** (ÙÛŒÚ†Ø±Ù‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯)

---

## ğŸ”´ Ù…Ø´Ú©Ù„Ø§Øª Ø­ÛŒØ§ØªÛŒ (Critical Issues)

### 1. **Data Leakage Ø¯Ø± Preprocessing** âš ï¸âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** ÙÙˆØ±ÛŒ

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 2850-2865
X_train, y_train = self.fit_preprocess(X_train_filtered, y_train)
X_test = self.transform_preprocess(X_test_filtered)
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
- Ø§Ú¯Ø± `fit_preprocess` Ø´Ø§Ù…Ù„ feature selection/transformation Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù…Ø§Ø±ÛŒ Ú©Ù„ train Ø¨Ù‡ test Ù†Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÙÛŒÚ†Ø±Ù‡Ø§ Ø¯Ø± ØªØ³Øª Ø¨Ù‡ØªØ± Ø§Ø² ÙˆØ§Ù‚Ø¹ÛŒØª Ø¨Ù‡ Ù†Ø¸Ø± Ø¨Ø±Ø³Ù†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
# Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· statistical normalization (mean/std) Ø¯Ø± fit_preprocess Ø¨Ø§Ø´Ø¯
# Ù‡ÛŒÚ† feature selection Ù†Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø§Ø´Ø¯
# Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:
def fit_preprocess(self, X, y):
    """ÙÙ‚Ø· normalization/scaling - Ø¨Ø¯ÙˆÙ† feature selection"""
    # ÙÙ‚Ø· StandardScaler ÛŒØ§ MinMaxScaler
    # NO: feature selection, variance threshold, correlation removal
    pass
```

**ØªØ³Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ:**
```python
# Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ Ø¨Ù‡ Ú©Ø¯:
def validate_no_leakage_in_preprocess(self):
    X_dummy = pd.DataFrame(np.random.randn(100, 10))
    y_dummy = pd.Series(np.random.randint(0, 2, 100))
    
    cols_before = X_dummy.columns.tolist()
    X_processed, _ = self.fit_preprocess(X_dummy, y_dummy)
    cols_after = X_processed.columns.tolist()
    
    assert cols_before == cols_after, "Feature selection detected in preprocessing!"
```

---

### 2. **Target Calculation Leakage** âš ï¸âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** ÙÙˆØ±ÛŒ

**Ù…Ø´Ú©Ù„:**
```python
# Ù‡ÛŒÚ† validation Ø¨Ø±Ø§ÛŒ target calculation ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
# target Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
Ø¯Ø± ÙØ§Ø±Ú©Ø³ØŒ Ø§Ú¯Ø± target Ø§Ø² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ (forward-looking) Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯:
- ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‚ÙˆÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ù†Ø¯
- Ø¯Ø± ØªØ±ÛŒØ¯ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø¢Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢ÛŒÙ†Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ â†’ Ø¶Ø±Ø±

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def validate_target_calculation(self, df, target_col='target', price_col='close'):
    """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ target ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡"""
    
    # ØªØ³Øª 1: Target Ø¨Ø§ÛŒØ¯ shift Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ (Ù†Ù‡ forward-looking)
    target = df[target_col]
    price = df[price_col]
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ correlation Ø¨Ø§ future prices
    for future_shift in [1, 2, 5, 10, 20]:
        future_price = price.shift(-future_shift)
        corr = target.corr(future_price.dropna())
        
        if abs(corr) > 0.3:
            raise ValueError(
                f"âš ï¸ TARGET LEAKAGE DETECTED! "
                f"Correlation with future price (t+{future_shift}): {corr:.3f}\n"
                f"Target should NOT be correlated with future prices!"
            )
    
    # ØªØ³Øª 2: Target Ø¯Ø± index i Ù†Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ price Ø¯Ø± index i+1 ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ø§Ø´Ø¯
    # Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· Ø¨Ù‡ price ØªØ§ index i ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ø§Ø´Ø¯
    logging.info("âœ“ Target calculation validated - NO future leakage detected")
```

**ØªØ³Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ:**
```python
# Ù…Ø«Ø§Ù„ target Ø¯Ø±Ø³Øª Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ú©Ø³:
def calculate_safe_target(df, horizon=10):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ target Ø¨Ø¯ÙˆÙ† leakage"""
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² return Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ - Ø§Ù…Ø§ label Ø¯Ø± Ø²Ù…Ø§Ù† t
    future_return = df['close'].shift(-horizon) / df['close'] - 1
    
    # Label: Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ±ÙˆØ¯ØŸ
    # Ø§ÛŒÙ† label Ø¯Ø± Ø²Ù…Ø§Ù† t Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ù‚Ø¨Ù„ Ø§Ø² horizon)
    target = (future_return > 0).astype(int)
    
    # âš ï¸ Ù…Ù‡Ù…: Ø§ÛŒÙ† target Ø±Ø§ shift Ù†Ú©Ù†ÛŒØ¯!
    # Ú†ÙˆÙ† future_return Ù‚Ø¨Ù„Ø§ shift Ø´Ø¯Ù‡
    
    return target.iloc[:-horizon]  # Ø­Ø°Ù last horizon rows Ú©Ù‡ nan Ø¯Ø§Ø±Ù†Ø¯
```

---

### 3. **SHAP Calculation Ø¨Ø¯ÙˆÙ† Proper Baseline** âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ø¨Ø§Ù„Ø§

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 1250-1280: SHAP analysis
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_sample)
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
- SHAP Ø¨Ø¯ÙˆÙ† background data Ù…Ù†Ø§Ø³Ø¨ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†ØªØ§ÛŒØ¬ bias Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
- Ø¨Ø±Ø§ÛŒ time-seriesØŒ Ø¨Ø§ÛŒØ¯ baseline Ø§Ø² train set Ø¨Ø§Ø´Ø¯ (Ù†Ù‡ random)

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def shap_importance_analysis_fixed(self, X_train, y_train, n_runs=5):
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² KMeans Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ representative background
    from sklearn.cluster import KMeans
    
    # Ø§Ù†ØªØ®Ø§Ø¨ 100 Ù†Ù…ÙˆÙ†Ù‡ representative Ø§Ø² train
    if len(X_train) > 100:
        kmeans = KMeans(n_clusters=100, random_state=self.random_state)
        kmeans.fit(X_train)
        background = X_train.iloc[
            np.argmin(np.linalg.norm(X_train - kmeans.cluster_centers_[:, None], axis=2), axis=1)
        ]
    else:
        background = X_train
    
    # SHAP Ø¨Ø§ background Ù…Ù†Ø§Ø³Ø¨
    explainer = shap.TreeExplainer(model, data=background)
    shap_values = explainer.shap_values(X_sample)
    
    # Ù…Ù‡Ù…: check Ú©Ù†ÛŒØ¯ shap_values[0] Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ø®ÙˆØ¯ shap_values
    if isinstance(shap_values, list):
        shap_values = shap_values[1]  # Ø¨Ø±Ø§ÛŒ binary classification
    
    return shap_values
```

---

### 4. **Adversarial Validation Ù†Ø§Ø¯Ø±Ø³Øª** âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ø¨Ø§Ù„Ø§

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 1450-1480: adversarial validation
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡Ù…Ù‡ train+test Ø¨Ø±Ø§ÛŒ training model
# Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ distribution shift ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´ÙˆØ¯
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
Ø¯Ø± ÙØ§Ø±Ú©Ø³ØŒ Ø¨Ø§Ø²Ø§Ø± ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (regime change). Ø§Ú¯Ø± adversarial validation Ø¯Ø±Ø³Øª Ú©Ø§Ø± Ù†Ú©Ù†Ø¯:
- ÙÛŒÚ†Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ÙÙ‚Ø· Ø¯Ø± ÛŒÚ© regime Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ØŒ Ù‚ÙˆÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
- Ø¯Ø± regime Ø¬Ø¯ÛŒØ¯ØŒ Ø§ÛŒÙ† ÙÛŒÚ†Ø±Ù‡Ø§ fail Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def adversarial_validation_fixed(self, X_train, X_test):
    """ØªØ´Ø®ÛŒØµ distribution shift Ø¨ÛŒÙ† train Ùˆ test"""
    
    # Ù…Ù‡Ù…: Ø§Ø² temporal split Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
    # train = Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ØŒ test = Ø¬Ø¯ÛŒØ¯ØªØ±
    
    X_combined = pd.concat([
        X_train.assign(is_test=0),
        X_test.assign(is_test=1)
    ], axis=0).reset_index(drop=True)
    
    y_combined = X_combined['is_test']
    X_combined = X_combined.drop('is_test', axis=1)
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² stratified split Ø¨Ø±Ø§ÛŒ balance
    from sklearn.model_selection import StratifiedKFold
    
    cv_scores = []
    cv = StratifiedKFold(n_splits=5, shuffle=False)  # shuffle=False Ø¨Ø±Ø§ÛŒ time-series
    
    for train_idx, val_idx in cv.split(X_combined, y_combined):
        model = lgb.LGBMClassifier(n_estimators=100, random_state=42)
        model.fit(X_combined.iloc[train_idx], y_combined.iloc[train_idx])
        
        y_pred = model.predict_proba(X_combined.iloc[val_idx])[:, 1]
        auc = roc_auc_score(y_combined.iloc[val_idx], y_pred)
        cv_scores.append(auc)
    
    mean_auc = np.mean(cv_scores)
    
    # ØªÙØ³ÛŒØ±:
    # AUC â‰ˆ 0.5: Ù‡ÛŒÚ† distribution shift ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ø®ÙˆØ¨)
    # AUC > 0.7: distribution shift Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ (Ø®Ø·Ø±Ù†Ø§Ú©!)
    # AUC > 0.9: distribution shift Ø´Ø¯ÛŒØ¯ (Ø¨Ø³ÛŒØ§Ø± Ø®Ø·Ø±Ù†Ø§Ú©!)
    
    if mean_auc > 0.9:
        logging.error(f"âš ï¸âš ï¸âš ï¸ SEVERE DISTRIBUTION SHIFT! AUC={mean_auc:.3f}")
        logging.error("Model will likely FAIL in real trading!")
    elif mean_auc > 0.7:
        logging.warning(f"âš ï¸ Significant distribution shift detected: AUC={mean_auc:.3f}")
    else:
        logging.info(f"âœ“ Distribution shift acceptable: AUC={mean_auc:.3f}")
    
    # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ shift-prone
    feature_importance = model.feature_importances_
    high_shift_features = X_combined.columns[feature_importance > np.percentile(feature_importance, 90)]
    
    return {
        'auc': mean_auc,
        'high_shift_features': high_shift_features.tolist(),
        'cv_scores': cv_scores
    }
```

---

### 5. **PBO Calculation Ø¨Ø§ Single Split** âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ø¨Ø§Ù„Ø§

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 2150: calculate_pbo_with_multiple_strategies
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© split Ø³Ø§Ø¯Ù‡ train/test
# Ø§ÛŒÙ† Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ overfitting Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ø¯
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
PBO (Probability of Backtest Overfitting) Ø¨Ø§ÛŒØ¯ Ø¨Ø§ CSCV Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯ (Bailey 2014).
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² single split:
- Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ robustness Ø±Ø§ ØªØ³Øª Ú©Ù†Ø¯
- ÛŒÚ© split Ø®ÙˆØ´â€ŒØ´Ø§Ù†Ø³ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ PBO Ù¾Ø§ÛŒÛŒÙ† Ø¯Ø±ÙˆØºÛŒÙ† Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def calculate_pbo_with_cscv_fixed(self, X, y, n_scenarios=16):
    """PBO Ø¨Ø§ CSCV - Ø±ÙˆØ´ ØµØ­ÛŒØ­ Bailey (2014)"""
    
    from itertools import combinations
    
    n = len(X)
    n_groups = 6
    group_size = n // n_groups
    
    # Ø§ÛŒØ¬Ø§Ø¯ groups temporal
    groups = []
    for i in range(n_groups):
        start_idx = i * group_size
        end_idx = min((i+1) * group_size, n)
        groups.append(np.arange(start_idx, end_idx))
    
    # ØªÙ…Ø§Ù… combinations Ø¨Ø±Ø§ÛŒ test set
    test_combinations = list(combinations(range(n_groups), 2))
    
    if len(test_combinations) > n_scenarios:
        # Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ scenarios
        rng = np.random.default_rng(self.random_state)
        selected = rng.choice(len(test_combinations), n_scenarios, replace=False)
        test_combinations = [test_combinations[i] for i in selected]
    
    pbo_values = []
    
    for test_fold_1, test_fold_2 in test_combinations:
        # Train: Ø¨Ù‚ÛŒÙ‡ folds
        train_folds = [i for i in range(n_groups) if i not in [test_fold_1, test_fold_2]]
        
        train_idx = np.concatenate([groups[i] for i in train_folds])
        test_idx = np.concatenate([groups[test_fold_1], groups[test_fold_2]])
        
        X_train = X.iloc[train_idx]
        y_train = y.iloc[train_idx]
        X_test = X.iloc[test_idx]
        y_test = y.iloc[test_idx]
        
        # ØªØ³Øª Ú†Ù†Ø¯ÛŒÙ† strategy (Ø¨Ø§ feature subsets Ù…Ø®ØªÙ„Ù)
        is_scores = []
        oos_scores = []
        
        for strategy_id in range(50):
            # Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ features
            n_features = np.random.randint(X.shape[1]//4, X.shape[1]//2)
            selected_features = np.random.choice(
                X.columns, 
                size=n_features, 
                replace=False
            )
            
            model = lgb.LGBMClassifier(n_estimators=100, random_state=strategy_id)
            model.fit(X_train[selected_features], y_train)
            
            # In-sample score
            y_pred_is = model.predict_proba(X_train[selected_features])[:, 1]
            is_score = roc_auc_score(y_train, y_pred_is)
            is_scores.append(is_score)
            
            # Out-of-sample score
            y_pred_oos = model.predict_proba(X_test[selected_features])[:, 1]
            oos_score = roc_auc_score(y_test, y_pred_oos)
            oos_scores.append(oos_score)
        
        # Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† scenario: Ø¨Ù‡ØªØ±ÛŒÙ† IS strategy Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        best_is_idx = np.argmax(is_scores)
        best_oos_score = oos_scores[best_is_idx]
        
        # Rank Ø¯Ø± OOS
        oos_rank = np.sum(np.array(oos_scores) > best_oos_score) + 1
        pbo_scenario = oos_rank / len(oos_scores)
        
        pbo_values.append(pbo_scenario)
    
    pbo_mean = np.mean(pbo_values)
    
    # ØªÙØ³ÛŒØ±:
    # PBO < 0.3: Ø¹Ø§Ù„ÛŒ - overfitting Ù¾Ø§ÛŒÛŒÙ†
    # PBO 0.3-0.5: Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„
    # PBO > 0.5: Ø®Ø·Ø± overfitting Ø¨Ø§Ù„Ø§
    # PBO > 0.7: overfitting Ø´Ø¯ÛŒØ¯ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯!
    
    if pbo_mean > 0.7:
        status = "ğŸ”´ CRITICAL: Severe overfitting - DO NOT USE"
    elif pbo_mean > 0.5:
        status = "ğŸŸ¡ WARNING: High overfitting risk"
    elif pbo_mean > 0.3:
        status = "ğŸŸ¢ ACCEPTABLE: Moderate overfitting"
    else:
        status = "âœ… EXCELLENT: Low overfitting risk"
    
    logging.info(f"PBO (CSCV): {pbo_mean:.3f} - {status}")
    
    return {
        'pbo': pbo_mean,
        'pbo_std': np.std(pbo_values),
        'n_scenarios': len(test_combinations),
        'interpretation': status,
        'is_overfitted': pbo_mean > 0.5
    }
```

---

### 6. **Embargo Gap Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ All Splits** âš ï¸âš ï¸
**Ø´Ø¯Øª:** Ù…ØªÙˆØ³Ø· ØªØ§ Ø¨Ø§Ù„Ø§ | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ø¨Ø§Ù„Ø§

**Ù…Ø´Ú©Ù„:**
```python
# embargo gap ÙÙ‚Ø· Ø¯Ø± nested CV Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
# Ø¯Ø± Ø³Ø§ÛŒØ± splits (Ù…Ø«Ù„ PBOØŒ walk-forward) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
Ø¯Ø± ÙØ§Ø±Ú©Ø³ Ø¨Ø§ autocorrelation Ø¨Ø§Ù„Ø§:
- Ø¨Ø¯ÙˆÙ† embargo gapØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² train Ø¨Ù‡ test Ù†Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- label_horizon Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ gap Ù„Ø­Ø§Ø¸ Ø´ÙˆØ¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def calculate_universal_embargo_gap(self, X, y, label_horizon=0):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ embargo gap Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… splits"""
    
    # Ø±ÙˆØ´ 1: Ø¨Ø± Ø§Ø³Ø§Ø³ ACF
    gap_acf = self.calculate_adaptive_gap(X, y, label_horizon)
    
    # Ø±ÙˆØ´ 2: Ø­Ø¯Ø§Ù‚Ù„ gap
    gap_min = max(
        label_horizon * 3,  # 3x label horizon
        int(0.02 * len(y)),  # 2% Ø§Ø² dataset
        10  # Ø­Ø¯Ø§Ù‚Ù„ Ù…Ø·Ù„Ù‚
    )
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨ÛŒØ´ØªØ±
    embargo_gap = max(gap_acf, gap_min)
    
    # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: Ù†Ø¨Ø§ÛŒØ¯ Ø¨ÛŒØ´ Ø§Ø² 10% dataset Ø¨Ø§Ø´Ø¯
    embargo_gap = min(embargo_gap, int(0.1 * len(y)))
    
    logging.info(f"Embargo gap calculated: {embargo_gap} samples")
    logging.info(f"  - ACF-based: {gap_acf}")
    logging.info(f"  - Minimum required: {gap_min}")
    logging.info(f"  - Final (max): {embargo_gap}")
    
    return embargo_gap
```

**Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù‡Ù…Ù‡ Ø¬Ø§:**
```python
# Ø¯Ø± temporal_split
def temporal_split(self, X, y, test_size=0.2, label_horizon=0):
    embargo_gap = self.calculate_universal_embargo_gap(X, y, label_horizon)
    
    n = len(X)
    test_samples = int(n * test_size)
    
    train_end = n - test_samples - embargo_gap
    test_start = train_end + embargo_gap
    
    return X.iloc[:train_end], X.iloc[test_start:], y.iloc[:train_end], y.iloc[test_start:]

# Ø¯Ø± PBO
def calculate_pbo_with_proper_gap(self, X, y):
    embargo_gap = self.calculate_universal_embargo_gap(X, y, self.label_horizon)
    
    n = len(X)
    is_end = n // 2
    oos_start = is_end + embargo_gap
    
    # ... rest of PBO calculation

# Ø¯Ø± Walk-Forward
def walk_forward_with_proper_gap(self, X, y):
    embargo_gap = self.calculate_universal_embargo_gap(X, y, self.label_horizon)
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² gap Ø¯Ø± Ù‡Ø± fold
    # ... rest of walk-forward
```

---

### 7. **Multicollinearity Handling Ù†Ø§Ù…Ù†Ø§Ø³Ø¨** âš ï¸
**Ø´Ø¯Øª:** Ù…ØªÙˆØ³Ø· | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ù…ØªÙˆØ³Ø·

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 2900: remove_redundant_features Ø¨Ø§ threshold=0.95
# Ø§ÛŒÙ† threshold Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§Ø³Øª
# Ù‡Ù…Ú†Ù†ÛŒÙ† ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

**Ú†Ø±Ø§ Ù…Ø´Ú©Ù„ Ø§Ø³Øª:**
- ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø¨Ø§ correlation 0.85-0.95 Ù‡Ù†ÙˆØ² redundant Ù‡Ø³ØªÙ†Ø¯
- Ø¨Ø§ÛŒØ¯ iterative removal Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯
- Ø¨Ø§ÛŒØ¯ VIF Ù†ÛŒØ² Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆØ¯

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def remove_multicollinearity_comprehensive(self, X, threshold_corr=0.85, threshold_vif=10):
    """Ø­Ø°Ù Ø¬Ø§Ù…Ø¹ multicollinearity"""
    
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    
    logging.info(f"Removing multicollinearity: corr>{threshold_corr}, VIF>{threshold_vif}")
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: Ø­Ø°Ù correlation Ø¨Ø§Ù„Ø§ (iterative)
    X_reduced = X.copy()
    removed_features = []
    
    while True:
        corr_matrix = X_reduced.corr().abs()
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† correlation
        upper_tri = corr_matrix.where(
            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
        )
        
        high_corr_pairs = [
            (col, row, corr_matrix.loc[row, col])
            for col in upper_tri.columns
            for row in upper_tri.index
            if upper_tri.loc[row, col] > threshold_corr
        ]
        
        if not high_corr_pairs:
            break
        
        # Ø­Ø°Ù feature Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† mean correlation
        mean_corrs = corr_matrix.mean()
        to_drop = max(
            [pair[0] for pair in high_corr_pairs] + [pair[1] for pair in high_corr_pairs],
            key=lambda x: mean_corrs[x]
        )
        
        X_reduced = X_reduced.drop(columns=[to_drop])
        removed_features.append(to_drop)
        
        logging.debug(f"Removed {to_drop} (high correlation)")
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø¨Ø±Ø±Ø³ÛŒ VIF
    if len(X_reduced.columns) > 1:
        while True:
            vif_data = pd.DataFrame({
                'feature': X_reduced.columns,
                'VIF': [
                    variance_inflation_factor(X_reduced.values, i)
                    for i in range(len(X_reduced.columns))
                ]
            })
            
            max_vif = vif_data['VIF'].max()
            
            if max_vif <= threshold_vif or len(X_reduced.columns) <= 2:
                break
            
            # Ø­Ø°Ù feature Ø¨Ø§ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† VIF
            to_drop = vif_data.loc[vif_data['VIF'].idxmax(), 'feature']
            X_reduced = X_reduced.drop(columns=[to_drop])
            removed_features.append(to_drop)
            
            logging.debug(f"Removed {to_drop} (VIF={max_vif:.2f})")
    
    logging.info(f"Multicollinearity removal: {len(X.columns)} -> {len(X_reduced.columns)}")
    logging.info(f"Removed {len(removed_features)} features")
    
    return X_reduced, removed_features
```

---

### 8. **Stability Selection Ø¨Ø§ Threshold Ø«Ø§Ø¨Øª** âš ï¸
**Ø´Ø¯Øª:** Ù…ØªÙˆØ³Ø· | **Ø§ÙˆÙ„ÙˆÛŒØª Ø±ÙØ¹:** Ù…ØªÙˆØ³Ø·

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 1850: stability threshold = 0.6 (Ø«Ø§Ø¨Øª)
# Ø§ÛŒÙ† threshold Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ datasets Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª
```

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def adaptive_stability_threshold_improved(
    self, 
    n_features, 
    n_iterations=100, 
    target_fdr=0.05,
    dataset_size=1000
):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ threshold Ø¨Ø± Ø§Ø³Ø§Ø³ dataset Ùˆ expected FDR"""
    
    # ÙØ±Ù…ÙˆÙ„ Bailey & Lopez de Prado
    # threshold = E[V] / S
    # Ú©Ù‡ V = false discoveries, S = total selections
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ expected false discoveries
    E_V = n_features * target_fdr
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ expected selections (Ø¨Ø± Ø§Ø³Ø§Ø³ stability)
    # Ø¨Ø±Ø§ÛŒ dataset Ú©ÙˆÚ†Ú©: threshold Ø¨Ø§Ù„Ø§ØªØ±
    # Ø¨Ø±Ø§ÛŒ dataset Ø¨Ø²Ø±Ú¯: threshold Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
    
    if dataset_size < 500:
        base_threshold = 0.75
    elif dataset_size < 1000:
        base_threshold = 0.70
    elif dataset_size < 5000:
        base_threshold = 0.65
    else:
        base_threshold = 0.60
    
    # adjustment Ø¨Ø± Ø§Ø³Ø§Ø³ iterations
    if n_iterations < 50:
        base_threshold += 0.05
    elif n_iterations > 200:
        base_threshold -= 0.05
    
    # adjustment Ø¨Ø± Ø§Ø³Ø§Ø³ target FDR
    fdr_adjustment = 0.4 * np.sqrt(max(0.0, 1.0 - float(target_fdr)))
    
    threshold = base_threshold + fdr_adjustment
    threshold = np.clip(threshold, 0.5, 0.95)
    
    logging.info(f"Adaptive stability threshold: {threshold:.3f}")
    logging.info(f"  - Dataset size: {dataset_size}")
    logging.info(f"  - Iterations: {n_iterations}")
    logging.info(f"  - Target FDR: {target_fdr}")
    
    return float(threshold)
```

---

## ğŸŸ¡ Ù…Ø´Ú©Ù„Ø§Øª Ù…Ù‡Ù… (High Priority Issues)

### 9. **Quick Prefilter Ù…Ù…Ú©Ù† Ø§Ø³Øª Feature Selection Leakage Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯**

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 2710: quick_prefilter
# Ø¢ÛŒØ§ ÙˆØ§Ù‚Ø¹Ø§ ÙÙ‚Ø· statistical Ø§Ø³ØªØŸ
```

**ØªØ³Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ:**
```python
def validate_prefilter_no_leakage(self):
    """Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¹Ø¯Ù… leakage Ø¯Ø± prefilter"""
    
    # Ø§ÛŒØ¬Ø§Ø¯ dummy data Ø¨Ø§ features Ú©Ù‡ correlation Ø¨Ø§ target Ø¯Ø§Ø±Ù†Ø¯
    n_samples = 1000
    n_features = 50
    
    X = pd.DataFrame(np.random.randn(n_samples, n_features))
    y = pd.Series(np.random.randint(0, 2, n_samples))
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† features Ø¨Ø§ correlation Ø¹Ù…Ø¯ÛŒ
    X['good_feature'] = y + np.random.randn(n_samples) * 0.1
    X['bad_feature'] = np.random.randn(n_samples)
    
    # Ø§Ø¬Ø±Ø§ÛŒ prefilter
    X_filtered, dropped = self.quick_prefilter(X, y)
    
    # Ø¨Ø±Ø±Ø³ÛŒ: Ø¢ÛŒØ§ good_feature drop Ù†Ø´Ø¯Ù‡ØŸ
    assert 'good_feature' in X_filtered.columns, "Good feature was dropped!"
    
    # Ø¨Ø±Ø±Ø³ÛŒ: Ø¢ÛŒØ§ ÙÙ‚Ø· statistical filters Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ØŸ
    # prefilter Ù†Ø¨Ø§ÛŒØ¯ features Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ importance drop Ú©Ù†Ø¯
    
    # ØªØ³Øª: prefilter Ø¨Ø§ÛŒØ¯ deterministic Ø¨Ø§Ø´Ø¯
    X_filtered_2, dropped_2 = self.quick_prefilter(X, y)
    assert set(dropped) == set(dropped_2), "Prefilter is not deterministic!"
    
    logging.info("âœ“ Prefilter validated - NO feature selection leakage")
```

---

### 10. **Nested CV Ø¨Ø§ Inner Splits Ú©Ù…**

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 1965: n_inner_splits = 3 (default)
# Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ hyperparameter tuning Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª
```

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def nested_cross_validation_improved(
    self, 
    X, 
    y, 
    n_outer_splits=5, 
    n_inner_splits=5  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 3 Ø¨Ù‡ 5
):
    # Ù‡Ù…Ú†Ù†ÛŒÙ†: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² random search Ø¨Ù‡ Ø¬Ø§ÛŒ grid search
    # Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø§ validation Ø¨Ù‡ØªØ±
    
    from sklearn.model_selection import RandomizedSearchCV
    
    param_distributions = {
        'n_estimators': [100, 200, 300, 500],
        'learning_rate': [0.01, 0.05, 0.1],
        'max_depth': [3, 5, 7, 9],
        'num_leaves': [15, 31, 63, 127]
    }
    
    # ... rest of nested CV
```

---

### 11. **SHAP Sample Size Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Large Datasets**

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 1250: shap_sample_size Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®ÛŒÙ„ÛŒ Ú©ÙˆÚ†Ú© Ø¨Ø§Ø´Ø¯
```

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def calculate_optimal_shap_sample_size(self, n_total, n_features):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ sample size Ø¨Ø±Ø§ÛŒ SHAP"""
    
    # ÙØ±Ù…ÙˆÙ„: 
    # - Ø­Ø¯Ø§Ù‚Ù„: 100 * sqrt(n_features)
    # - Ø­Ø¯Ø§Ú©Ø«Ø±: 10000 (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)
    # - ØªØ±Ø¬ÛŒØ­ÛŒ: 1% Ø§Ø² dataset ÛŒØ§ 1000 (Ù‡Ø±Ú©Ø¯Ø§Ù… Ø¨ÛŒØ´ØªØ±)
    
    min_required = int(100 * np.sqrt(n_features))
    preferred = max(int(0.01 * n_total), 1000)
    max_allowed = 10000
    
    sample_size = np.clip(preferred, min_required, max_allowed)
    
    # Ø§Ú¯Ø± dataset Ú©ÙˆÚ†Ú© Ø§Ø³ØªØŒ Ø§Ø² Ù‡Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if n_total < sample_size:
        sample_size = n_total
    
    logging.info(f"SHAP sample size: {sample_size} (total: {n_total})")
    
    return sample_size
```

---

### 12. **Walk-Forward Analysis Ø¨Ø¯ÙˆÙ† Adaptive Retraining**

**Ù…Ø´Ú©Ù„:**
```python
# Ø®Ø· 2500: retrain_frequency Ø«Ø§Ø¨Øª Ø§Ø³Øª
# Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ performance degradation adaptive Ø¨Ø§Ø´Ø¯
```

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
```python
def walk_forward_adaptive(self, X, y, initial_retrain_freq=5):
    """Walk-forward Ø¨Ø§ retraining adaptive"""
    
    retrain_freq = initial_retrain_freq
    performance_window = []
    
    for fold in range(n_splits):
        # ... training & testing
        
        performance_window.append(score)
        
        # Ø¨Ø±Ø±Ø³ÛŒ degradation
        if len(performance_window) >= 5:
            recent = np.mean(performance_window[-3:])
            older = np.mean(performance_window[-5:-3])
            
            degradation = older - recent
            
            if degradation > 0.05:  # 5% degradation
                # Ø§ÙØ²Ø§ÛŒØ´ frequency
                retrain_freq = max(1, retrain_freq - 1)
                logging.warning(f"Performance degraded {degradation:.3f}, "
                               f"increasing retrain freq to {retrain_freq}")
            elif degradation < -0.02:  # improvement
                # Ú©Ø§Ù‡Ø´ frequency (Ú©Ù…â€ŒØªØ± retrain)
                retrain_freq = min(10, retrain_freq + 1)
                logging.info(f"Performance stable, "
                            f"decreasing retrain freq to {retrain_freq}")
```

---

## ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒØ´Ø¯Ù‡ (Recommended Improvements)

### 13. **Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Combinatorial Purged CV**

```python
def combinatorial_purged_cv_implementation(self, X, y, n_splits=6, n_test_groups=2):
    """CPCV Ø¨Ø±Ø§ÛŒ time-series - Ø±ÙˆØ´ Lopez de Prado"""
    
    from mlfinlab.cross_validation import CombinatorialPurgedCV
    
    cv = CombinatorialPurgedCV(
        n_splits=n_splits,
        n_test_groups=n_test_groups,
        embargo_pct=0.01,
        purging=True
    )
    
    scores = []
    
    for train_idx, test_idx in cv.split(X):
        # ensure no overlap
        assert len(set(train_idx) & set(test_idx)) == 0
        
        # ... training & validation
        
    return scores
```

---

### 14. **Ø§ÙØ²ÙˆØ¯Ù† Deflated Sharpe Ratio**

```python
def calculate_deflated_sharpe_comprehensive(
    self,
    returns,
    n_trials=100,
    benchmark_sr=0.0
):
    """DSR Ø¨Ø§ ÙØ±Ù…ÙˆÙ„ Ú©Ø§Ù…Ù„ Bailey & Lopez de Prado"""
    
    from scipy.stats import norm, skew, kurtosis
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Sharpe
    sr = np.mean(returns) / np.std(returns) * np.sqrt(252)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ moments
    skewness = skew(returns)
    kurt = kurtosis(returns)
    
    # Variance of Sharpe
    T = len(returns)
    var_sr = (1/T) * (
        1 + 0.5 * sr**2 
        - skewness * sr 
        + (kurt/4) * sr**2
    )
    
    # Expected maximum SR under null (no skill)
    euler = 0.5772156649
    sr_threshold = np.sqrt(var_sr) * (
        (1 - euler) * norm.ppf(1 - 1/n_trials) +
        euler * norm.ppf(1 - 1/(n_trials * np.e))
    )
    
    # Deflated Sharpe
    dsr = (sr - sr_threshold) / np.sqrt(var_sr)
    
    # Probabilistic Sharpe Ratio
    psr = norm.cdf(dsr)
    
    logging.info(f"Sharpe: {sr:.3f}, DSR: {dsr:.3f}, PSR: {psr:.3f}")
    
    return {
        'sharpe': sr,
        'deflated_sharpe': dsr,
        'probabilistic_sharpe': psr,
        'sr_threshold': sr_threshold,
        'is_significant': psr > 0.95
    }
```

---

### 15. **Feature Importance Ø¨Ø§ Permutation Ø¯Ø± Time-Series**

```python
def permutation_importance_timeseries(self, X, y, model, n_repeats=10):
    """Permutation importance Ú©Ù‡ temporal structure Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    
    # baseline score
    y_pred = model.predict(X)
    baseline_score = self._calculate_score(y, y_pred)
    
    importances = []
    
    for feature in X.columns:
        feature_importances = []
        
        for repeat in range(n_repeats):
            X_permuted = X.copy()
            
            # Ù…Ù‡Ù…: block permutation Ø¨Ø±Ø§ÛŒ time-series
            # Ù†Ù‡ random permutation
            block_size = 20  # ÛŒØ§ 5% Ø§Ø² dataset
            
            n_blocks = len(X) // block_size
            block_indices = np.arange(n_blocks)
            np.random.shuffle(block_indices)
            
            permuted_values = []
            for block_idx in block_indices:
                start = block_idx * block_size
                end = min(start + block_size, len(X))
                permuted_values.extend(X[feature].iloc[start:end].values)
            
            X_permuted[feature] = permuted_values[:len(X)]
            
            # score Ø¨Ø§ permuted feature
            y_pred_perm = model.predict(X_permuted)
            perm_score = self._calculate_score(y, y_pred_perm)
            
            importance = baseline_score - perm_score
            feature_importances.append(importance)
        
        importances.append({
            'feature': feature,
            'importance_mean': np.mean(feature_importances),
            'importance_std': np.std(feature_importances)
        })
    
    return pd.DataFrame(importances).sort_values('importance_mean', ascending=False)
```

---

### 16. **Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Maximum Drawdown Analysis**

```python
def analyze_maximum_drawdown(self, returns):
    """ØªØ­Ù„ÛŒÙ„ MDD Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ risk"""
    
    cumulative = np.cumsum(returns)
    running_max = np.maximum.accumulate(cumulative)
    drawdown = running_max - cumulative
    
    max_dd = np.max(drawdown)
    max_dd_pct = max_dd / (running_max[np.argmax(drawdown)] + 1e-10)
    
    # Duration of max drawdown
    dd_start = np.argmax(running_max[:np.argmax(drawdown)])
    dd_end = np.argmax(drawdown)
    dd_duration = dd_end - dd_start
    
    # Recovery time
    if dd_end < len(cumulative) - 1:
        recovery_idx = np.where(cumulative[dd_end:] >= running_max[dd_end])[0]
        recovery_time = recovery_idx[0] if len(recovery_idx) > 0 else None
    else:
        recovery_time = None
    
    # Calmar Ratio
    annual_return = np.mean(returns) * 252
    calmar = annual_return / max_dd if max_dd > 0 else 0
    
    logging.info(f"Maximum Drawdown Analysis:")
    logging.info(f"  - Max DD: {max_dd:.4f} ({max_dd_pct:.1%})")
    logging.info(f"  - Duration: {dd_duration} periods")
    logging.info(f"  - Recovery: {recovery_time} periods" if recovery_time else "  - Not recovered")
    logging.info(f"  - Calmar Ratio: {calmar:.3f}")
    
    return {
        'max_drawdown': max_dd,
        'max_drawdown_pct': max_dd_pct,
        'drawdown_duration': dd_duration,
        'recovery_time': recovery_time,
        'calmar_ratio': calmar
    }
```

---

### 17. **Feature Stability Ø¨Ø§ Bootstrap**

```python
def bootstrap_feature_stability(self, X, y, n_bootstrap=100):
    """ØªØ³Øª stability Ø¨Ø§ bootstrap sampling"""
    
    feature_selections = []
    
    for bootstrap_iter in range(n_bootstrap):
        # bootstrap sample (Ø¨Ø§ replacement)
        indices = np.random.choice(len(X), size=len(X), replace=True)
        X_boot = X.iloc[indices]
        y_boot = y.iloc[indices]
        
        # feature selection
        model = lgb.LGBMClassifier(n_estimators=100)
        model.fit(X_boot, y_boot)
        
        # top 20% features
        importances = model.feature_importances_
        threshold = np.percentile(importances, 80)
        selected = X.columns[importances >= threshold].tolist()
        
        feature_selections.append(selected)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ stability score
    all_features = X.columns.tolist()
    selection_freq = {
        feature: sum(1 for sel in feature_selections if feature in sel) / n_bootstrap
        for feature in all_features
    }
    
    # features Ø¨Ø§ selection frequency > 0.7 = stable
    stable_features = [f for f, freq in selection_freq.items() if freq > 0.7]
    
    logging.info(f"Bootstrap stability: {len(stable_features)}/{len(all_features)} stable features")
    
    return {
        'selection_frequency': selection_freq,
        'stable_features': stable_features,
        'instability_score': 1 - np.mean(list(selection_freq.values()))
    }
```

---

### 18. **Monte Carlo Permutation Test**

```python
def monte_carlo_permutation_test(self, X, y, model, n_permutations=1000):
    """ØªØ³Øª significance Ø¨Ø§ permutation test"""
    
    # baseline performance
    model.fit(X, y)
    y_pred = model.predict(X)
    baseline_score = roc_auc_score(y, y_pred)
    
    # permutation distribution
    null_scores = []
    
    for perm_iter in range(n_permutations):
        # shuffle target
        y_shuffled = y.sample(frac=1, random_state=perm_iter).reset_index(drop=True)
        
        model_null = lgb.LGBMClassifier(n_estimators=100, random_state=perm_iter)
        model_null.fit(X, y_shuffled)
        
        y_pred_null = model_null.predict(X)
        null_score = roc_auc_score(y_shuffled, y_pred_null)
        null_scores.append(null_score)
    
    # p-value
    p_value = np.mean(np.array(null_scores) >= baseline_score)
    
    # effect size
    effect_size = (baseline_score - np.mean(null_scores)) / np.std(null_scores)
    
    logging.info(f"Permutation Test:")
    logging.info(f"  - Baseline AUC: {baseline_score:.4f}")
    logging.info(f"  - Null mean AUC: {np.mean(null_scores):.4f}")
    logging.info(f"  - P-value: {p_value:.4f}")
    logging.info(f"  - Effect size: {effect_size:.3f}")
    
    if p_value < 0.01:
        interpretation = "âœ… HIGHLY SIGNIFICANT - Features have strong predictive power"
    elif p_value < 0.05:
        interpretation = "âœ“ SIGNIFICANT - Features are predictive"
    elif p_value < 0.1:
        interpretation = "âš ï¸ MARGINAL - Weak evidence of predictive power"
    else:
        interpretation = "âŒ NOT SIGNIFICANT - Features lack predictive power"
    
    logging.info(f"  - {interpretation}")
    
    return {
        'baseline_score': baseline_score,
        'null_mean': np.mean(null_scores),
        'null_std': np.std(null_scores),
        'p_value': p_value,
        'effect_size': effect_size,
        'is_significant': p_value < 0.05,
        'interpretation': interpretation
    }
```

---

## ğŸ“Š Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ 2025

### 19. **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Cross-Validation Ù…Ø¯Ø±Ù†**

Ø¨Ø±Ø§ÛŒ time-series financial data Ø¯Ø± 2025:

1. **Time Series Split Ø¨Ø§ Purging**
2. **Combinatorial Purged CV (CPCV)**
3. **Walk-Forward Ø¨Ø§ Reanchoring**

```python
# âŒ Ù‚Ø¯ÛŒÙ…ÛŒ (2020)
from sklearn.model_selection import KFold

# âœ… Ø¬Ø¯ÛŒØ¯ (2025)
from sklearn.model_selection import TimeSeriesSplit

# âœ…âœ… Ø¨Ù‡ØªØ±ÛŒÙ† (2025)
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CPCV Ø¨Ø§ purging Ùˆ embargo
```

---

### 20. **Leakage Detection Automated**

```python
def automated_leakage_detection(self):
    """ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ÙˆØ§Ø¹ data leakage"""
    
    tests = [
        ('Target Leakage', self.test_target_leakage),
        ('Preprocessing Leakage', self.test_preprocessing_leakage),
        ('Feature Selection Leakage', self.test_feature_selection_leakage),
        ('Temporal Leakage', self.test_temporal_leakage),
        ('Train-Test Overlap', self.test_train_test_overlap)
    ]
    
    results = {}
    all_passed = True
    
    for test_name, test_func in tests:
        try:
            passed = test_func()
            results[test_name] = 'PASSED' if passed else 'FAILED'
            
            if not passed:
                all_passed = False
                logging.error(f"âŒ {test_name}: FAILED")
            else:
                logging.info(f"âœ“ {test_name}: PASSED")
        except Exception as e:
            results[test_name] = f'ERROR: {e}'
            all_passed = False
            logging.error(f"âŒ {test_name}: ERROR - {e}")
    
    if all_passed:
        logging.info("ğŸ‰ ALL LEAKAGE TESTS PASSED!")
    else:
        logging.error("âš ï¸ SOME LEAKAGE TESTS FAILED - REVIEW REQUIRED")
    
    return results, all_passed
```

---

### 21. **Robustness Score**

```python
def calculate_robustness_score(self, evaluation_results):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² robustness Ú©Ù„ÛŒ"""
    
    # Components:
    # 1. PBO (lower is better)
    # 2. PSR (higher is better)
    # 3. Performance stability (lower variance)
    # 4. Distribution shift (lower AUC)
    # 5. Feature stability (higher frequency)
    
    pbo = evaluation_results.get('pbo', 1.0)
    psr = evaluation_results.get('probabilistic_sharpe', 0.0)
    perf_std = evaluation_results.get('performance_std', 1.0)
    adv_auc = evaluation_results.get('adversarial_auc', 1.0)
    feat_stability = evaluation_results.get('feature_stability_mean', 0.0)
    
    # Scoring (0-100)
    score_pbo = (1 - pbo) * 25  # 0-25 points
    score_psr = psr * 25  # 0-25 points
    score_stability = (1 - min(perf_std, 1.0)) * 20  # 0-20 points
    score_shift = (1 - min(adv_auc, 1.0)) * 15  # 0-15 points
    score_features = feat_stability * 15  # 0-15 points
    
    total_score = (
        score_pbo +
        score_psr +
        score_stability +
        score_shift +
        score_features
    )
    
    # ØªÙØ³ÛŒØ±
    if total_score >= 85:
        interpretation = "ğŸŒŸ EXCELLENT - Ready for production"
    elif total_score >= 70:
        interpretation = "âœ… GOOD - Acceptable for trading"
    elif total_score >= 50:
        interpretation = "âš ï¸ FAIR - Use with caution"
    else:
        interpretation = "âŒ POOR - Not recommended for trading"
    
    logging.info(f"Robustness Score: {total_score:.1f}/100")
    logging.info(f"  - {interpretation}")
    logging.info(f"Component scores:")
    logging.info(f"  - PBO: {score_pbo:.1f}/25")
    logging.info(f"  - PSR: {score_psr:.1f}/25")
    logging.info(f"  - Stability: {score_stability:.1f}/20")
    logging.info(f"  - Distribution Shift: {score_shift:.1f}/15")
    logging.info(f"  - Feature Stability: {score_features:.1f}/15")
    
    return {
        'total_score': total_score,
        'interpretation': interpretation,
        'component_scores': {
            'pbo': score_pbo,
            'psr': score_psr,
            'stability': score_stability,
            'distribution_shift': score_shift,
            'feature_stability': score_features
        },
        'is_production_ready': total_score >= 70
    }
```

---

## ğŸ”§ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¯Ø§Ø±

### ÙØ§Ø² 1: Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø­ÛŒØ§ØªÛŒ (Ù‡ÙØªÙ‡ 1)

1. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `validate_target_calculation` Ø¨Ù‡ `__init__`
2. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `validate_no_leakage_in_preprocess` Ø¨Ù‡ `fit_preprocess`
3. âœ… Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ `calculate_pbo_with_multiple_strategies` Ø¨Ø§ `calculate_pbo_with_cscv_fixed`
4. âœ… Ø§ØµÙ„Ø§Ø­ `adversarial_validation` Ø¨Ø§ Ø±ÙˆØ´ fixed
5. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `calculate_universal_embargo_gap` Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù‡Ù…Ù‡ splits

**ØªØ³Øª:**
```python
# Ø§Ø¬Ø±Ø§ Ø¨Ø§ dataset Ú©ÙˆÚ†Ú©
python FSZ12-1-FIXED.py --test-mode --validate-leakage
```

---

### ÙØ§Ø² 2: Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… (Ù‡ÙØªÙ‡ 2)

6. âœ… Ø§ØµÙ„Ø§Ø­ `shap_importance_analysis` Ø¨Ø§ background Ù…Ù†Ø§Ø³Ø¨
7. âœ… Ø§ØµÙ„Ø§Ø­ `remove_multicollinearity` Ø¨Ù‡ `remove_multicollinearity_comprehensive`
8. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `calculate_deflated_sharpe_comprehensive`
9. âœ… Ø§ØµÙ„Ø§Ø­ `nested_cv` Ø¨Ø§ inner_splits=5

**ØªØ³Øª:**
```python
# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯
python compare_results.py --old FSZ12-1.py --new FSZ12-1-FIXED.py
```

---

### ÙØ§Ø² 3: Ø§ÙØ²ÙˆØ¯Ù† Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ (Ù‡ÙØªÙ‡ 3)

10. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `permutation_importance_timeseries`
11. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `bootstrap_feature_stability`
12. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `monte_carlo_permutation_test`
13. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `calculate_robustness_score`
14. âœ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† `automated_leakage_detection`

---

### ÙØ§Ø² 4: ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ (Ù‡ÙØªÙ‡ 4)

15. âœ… Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ø±ÙˆÛŒ Ú†Ù†Ø¯ dataset
16. âœ… Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†Ø³Ø®Ù‡ Ù‚Ø¨Ù„ÛŒ
17. âœ… Ù†ÙˆØ´ØªÙ† Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„
18. âœ… Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ production

---

## ğŸ“ Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ

Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ø±Ø¨Ø§Øª Ø¨Ø±Ø§ÛŒ ØªØ±ÛŒØ¯ ÙˆØ§Ù‚Ø¹ÛŒ:

### âœ… Data Leakage Prevention

- [ ] Target ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø°Ø´ØªÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡
- [ ] Preprocessing Ø¨Ø¯ÙˆÙ† feature selection
- [ ] Train/Test split temporal Ø¨Ø§ embargo gap
- [ ] Ù‡ÛŒÚ† overlap Ø¨ÛŒÙ† train Ùˆ test ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
- [ ] Feature selection ÙÙ‚Ø· Ø±ÙˆÛŒ train set

### âœ… Validation Quality

- [ ] PBO < 0.5 (ØªØ±Ø¬ÛŒØ­Ø§ < 0.3)
- [ ] PSR > 0.95 (Probabilistic Sharpe Ratio)
- [ ] Nested CV score stable (std < 0.05)
- [ ] Adversarial validation AUC < 0.7
- [ ] Walk-forward degradation < 0.05

### âœ… Feature Quality

- [ ] Feature stability > 0.7 (70% bootstrap frequency)
- [ ] Multicollinearity removed (VIF < 10)
- [ ] SHAP values consistent (CV < 0.2)
- [ ] Permutation importance significant (p < 0.05)
- [ ] No lookahead features detected

### âœ… Model Robustness

- [ ] Performance Ø¯Ø± Ú†Ù†Ø¯ regime Ù…Ø®ØªÙ„Ù ØªØ³Øª Ø´Ø¯Ù‡
- [ ] Maximum Drawdown Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ (< 20%)
- [ ] Calmar Ratio > 1.0
- [ ] Win Rate > 50%
- [ ] Profit Factor > 1.5

---

## ğŸ¯ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

### Ø®Ù„Ø§ØµÙ‡ Ù…Ø´Ú©Ù„Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:

**Ø­ÛŒØ§ØªÛŒ (Critical):** 8 Ù…ÙˆØ±Ø¯  
**Ù…Ù‡Ù… (High):** 4 Ù…ÙˆØ±Ø¯  
**Ù…ØªÙˆØ³Ø· (Medium):** 6 Ù…ÙˆØ±Ø¯  
**Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Recommended):** 4 Ù…ÙˆØ±Ø¯

**Ø¬Ù…Ø¹ Ú©Ù„:** 22 Ù…ÙˆØ±Ø¯

### Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø§ØµÙ„Ø§Ø­Ø§Øª:

1. ğŸ”´ **Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Target** - Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² future leakage
2. ğŸ”´ **PBO Ø¨Ø§ CSCV** - ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚ overfitting
3. ğŸ”´ **Embargo Gap Ø¬Ù‡Ø§Ù†ÛŒ** - Ø¯Ø± Ù‡Ù…Ù‡ splits
4. ğŸŸ¡ **Adversarial Validation Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡** - ØªØ´Ø®ÛŒØµ regime shift
5. ğŸŸ¡ **SHAP Ø¨Ø§ Background** - Ù†ØªØ§ÛŒØ¬ Ù…Ø¹ØªØ¨Ø±ØªØ±

### Ø§Ù…ØªÛŒØ§Ø² ÙØ¹Ù„ÛŒ Ú©Ø¯:

- **Data Leakage Prevention:** 6/10 âš ï¸
- **Validation Quality:** 7/10 âš ï¸
- **Feature Selection:** 8/10 âœ“
- **Model Robustness:** 6/10 âš ï¸

**Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ:** 6.75/10

### Ø§Ù…ØªÛŒØ§Ø² Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØµÙ„Ø§Ø­Ø§Øª:

- **Data Leakage Prevention:** 9.5/10 âœ…
- **Validation Quality:** 9/10 âœ…
- **Feature Selection:** 9/10 âœ…
- **Model Robustness:** 8.5/10 âœ…

**Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ:** 9/10 âœ…

---

## ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù…Ø±Ø§Ø¬Ø¹

1. **Bailey, D. H., & Lopez de Prado, M. (2014).** "The Deflated Sharpe Ratio: Correcting for Selection Bias, Backtest Overfitting, and Non-Normality"
2. **Bailey, D. H., Borwein, J., Lopez de Prado, M., & Zhu, Q. J. (2014).** "Probability of Backtest Overfitting"
3. **Parvandeh, S., et al. (2020).** "Consensus nested cross-validation" - Bioinformatics
4. **Starcke, J. et al. (2025).** "The Effect of Data Leakage and Feature Selection on Clinical ML" - PubMed
5. **Lopez de Prado, M. (2018).** "Advances in Financial Machine Learning" - Wiley

---

**ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´:** Û±Û¹ Ù†ÙˆØ§Ù…Ø¨Ø± Û²Û°Û²Ûµ  
**Ù†Ø³Ø®Ù‡:** 1.0  
**ÙˆØ¶Ø¹ÛŒØª:** Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ø§ØµÙ„Ø§Ø­ ÙÙˆØ±ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± production

**ØªÙˆØµÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ:** Ú©Ø¯ ÙØ¹Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ±ÛŒØ¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ **Ù†Ú©Ù†ÛŒØ¯** ØªØ§ Ø§ØµÙ„Ø§Ø­Ø§Øª ÙØ§Ø² 1 Ùˆ 2 Ø§Ø¹Ù…Ø§Ù„ Ø´ÙˆÙ†Ø¯. Ø®Ø·Ø± data leakage Ùˆ false positive Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ø§Ù„Ø§ Ø§Ø³Øª.
