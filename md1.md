# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ Ú©Ø§Ù…Ù„: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ LightGBM Ø¨Ø±Ø§ÛŒ ØªØ³Øª ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø¯Ù‚Øª
## ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ ØªÙ…Ø§Ù… Ø¯ÙˆØ±Ù‡Ø§ÛŒ ØªØ­Ù‚ÛŒÙ‚Ø§Øª + Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Data Leakage

**ØªØ§Ø±ÛŒØ®:** Ù†ÙˆØ§Ù…Ø¨Ø± 2025  
**Ù†Ø³Ø®Ù‡ LightGBM:** 4.6.0+  
**Ø§ÙˆÙ„ÙˆÛŒØª:** **Ø¯Ù‚Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± > Ø³Ø±Ø¹Øª Ùˆ Ø­Ø§ÙØ¸Ù‡**  
**Ù‡Ø¯Ù:** ØªØ³Øª Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…Ø¹ØªØ¨Ø± 3885 ÙÛŒÚ†Ø± TSfresh Ø¨Ø¯ÙˆÙ† Ù†Ø´Øª Ø¯Ø§Ø¯Ù‡ ÛŒØ§ Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´

---

## ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨

1. [Ø§ØµÙˆÙ„ Ø¨Ù†ÛŒØ§Ø¯ÛŒ: Ú†Ø±Ø§ Ø¯Ù‚Øª Ù…Ù‡Ù…â€ŒØªØ± Ø§Ø² Ø³Ø±Ø¹Øª Ø§Ø³Øª](#Ø§ØµÙˆÙ„)
2. [Ø¯ÙˆØ±Ù‡ Ø§ÙˆÙ„: Ø§ØµÙ„Ø§Ø­Ø§Øª Ø¨Ù†ÛŒØ§Ø¯ÛŒ](#Ø¯ÙˆØ±Ù‡-Ø§ÙˆÙ„)
3. [Ø¯ÙˆØ±Ù‡ Ø¯ÙˆÙ…: ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡](#Ø¯ÙˆØ±Ù‡-Ø¯ÙˆÙ…)
4. [Ø¯ÙˆØ±Ù‡ Ø³ÙˆÙ…: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ](#Ø¯ÙˆØ±Ù‡-Ø³ÙˆÙ…)
5. [Ø¯ÙˆØ±Ù‡ Ú†Ù‡Ø§Ø±Ù…: Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø¹Ù…ÛŒÙ‚](#Ø¯ÙˆØ±Ù‡-Ú†Ù‡Ø§Ø±Ù…)
6. [Ø¯ÙˆØ±Ù‡ Ù¾Ù†Ø¬Ù…: Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Data Leakage Ùˆ Overfitting](#Ø¯ÙˆØ±Ù‡-Ù¾Ù†Ø¬Ù…)
7. [Ú©Ø¯ Ù†Ù‡Ø§ÛŒÛŒ Production-Grade](#Ú©Ø¯-Ù†Ù‡Ø§ÛŒÛŒ)
8. [Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ú©Ø§Ù…Ù„](#Ú†Ú©-Ù„ÛŒØ³Øª)

---

## Ø§ØµÙˆÙ„ Ø¨Ù†ÛŒØ§Ø¯ÛŒ: Ú†Ø±Ø§ Ø¯Ù‚Øª Ù…Ù‡Ù…â€ŒØªØ± Ø§Ø² Ø³Ø±Ø¹Øª Ø§Ø³Øª

### Ø§Ù‡Ù…ÛŒØª Ø¯Ù‚Øª Ø¯Ø± Feature Selection

**ÛŒÚ© Ø§Ø´ØªØ¨Ø§Ù‡ Ø¯Ø± ØªØ³Øª ÙÛŒÚ†Ø±Ù‡Ø§ = ÙØ§Ø¬Ø¹Ù‡:**
- ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ù‚ÙˆÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ âŒ
- ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ Ø¨Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ù…Ø±Ù‡ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ âŒ
- Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø§Ø´ØªØ¨Ø§Ù‡ train Ù…ÛŒâ€ŒØ´ÙˆØ¯ âŒ
- Ù†ØªØ§ÛŒØ¬ Ø¯Ø± production ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ âŒ

### ÙÙ„Ø³ÙÙ‡ Ø·Ø±Ø§Ø­ÛŒ Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§

```
Ø¯Ù‚Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± ØªØ³Øª >>> Ø³Ø±Ø¹Øª Ø§Ø¬Ø±Ø§ >>> Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡
```

**Ø§ØµÙ„ Ø·Ù„Ø§ÛŒÛŒ:** ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ø§ÛŒØ¯ Ù‚Ø¯Ø±Øª Ø°Ø§ØªÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ù†Ù…Ø§ÛŒØ§Ù† Ú©Ù†Ù†Ø¯ØŒ Ù†Ù‡ Ù‚Ø¯Ø±Øª Ù…ØµÙ†ÙˆØ¹ÛŒ Ù†Ø§Ø´ÛŒ Ø§Ø²:
1. Data Leakage (Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢ÛŒÙ†Ø¯Ù‡)
2. Target Leakage (Ù†Ø´Øª target Ø¨Ù‡ features)
3. Overfitting (Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´)
4. Spurious Correlations (Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¹Ù„ÛŒ)

---

## Ø¯ÙˆØ±Ù‡ Ø§ÙˆÙ„: Ø§ØµÙ„Ø§Ø­Ø§Øª Ø¨Ù†ÛŒØ§Ø¯ÛŒ

### 1.1 Ù…Ø´Ú©Ù„ GOSS (Ø­ÛŒØ§ØªÛŒ)

**Ù…Ø´Ú©Ù„:**
```python
# âŒ Ø±ÙˆØ´ Ù…Ù†Ø³ÙˆØ® Ø´Ø¯Ù‡ (LightGBM < 4.0)
params = {'boosting_type': 'goss'}
```

**Ø±Ø§Ù‡Ú©Ø§Ø±:**
```python
# âœ… LightGBM 4.0+ (ØµØ­ÛŒØ­)
params = {
    'boosting_type': 'gbdt',
    'data_sample_strategy': 'goss',
    'top_rate': 0.2,
    'other_rate': 0.1
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** LightGBM 4.6 Documentation, GitHub #3182

---

### 1.2 CPU Optimization

```python
import psutil
import os

physical_cores = psutil.cpu_count(logical=False)
os.environ['OMP_NUM_THREADS'] = str(physical_cores)

params = {
    'num_threads': physical_cores,
    'force_col_wise': True,
    'deterministic': True
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #512, #4425

---

### 1.3 Validation Strategy (Ø­ÛŒØ§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª)

```python
# âŒ Ø§Ø´ØªØ¨Ø§Ù‡
valid_sets=[train_data, val_data]

# âœ… ØµØ­ÛŒØ­
valid_sets=[val_data]
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #82, #84, #278

---

### 1.4 Callbacks LightGBM 4.0+

```python
callbacks = [
    lgb.early_stopping(stopping_rounds=50),
    lgb.log_evaluation(period=0)
]
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #113, #5196

---

## Ø¯ÙˆØ±Ù‡ Ø¯ÙˆÙ…: ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

### 2.1 lgb.cv Native (Ø³Ø±Ø¹Øª 2-3x)

```python
cv_results = lgb.cv(
    params,
    train_data,
    num_boost_round=500,
    folds=custom_folds,
    stratified=False,
    return_cvbooster=True
)
```

**Ù…Ù†Ø§Ø¨Ø¹:** lightgbm.cv Documentation

---

### 2.2 Feature Importance: Gain vs Split (Ø­ÛŒØ§ØªÛŒ)

```python
# âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Gain
importance = model.feature_importance(importance_type='gain')
```

**Ú†Ø±Ø§ Gain Ø¨Ù‡ØªØ± Ø§Ø³Øª:**
- Split ÙÙ‚Ø· ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ Ù…ÛŒâ€ŒØ´Ù…Ø§Ø±Ø¯
- Gain Ú©ÛŒÙÛŒØª split Ø±Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
- Gain Ù…Ø¹ÛŒØ§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ù‡Ù…ÛŒØª Ø§Ø³Øª

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #4255, #132

---

### 2.3 Purged Time Series Split (Ø­ÛŒØ§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª)

```python
class PurgedGroupTimeSeriesSplit:
    def __init__(self, n_splits=5, purge_gap=10, embargo_gap=5):
        self.n_splits = n_splits
        self.purge_gap = purge_gap
        self.embargo_gap = embargo_gap
    
    def split(self, X, y=None, groups=None):
        n_samples = len(X)
        fold_size = n_samples // (self.n_splits + 1)
        
        for i in range(self.n_splits):
            test_start = (i + 1) * fold_size
            test_end = test_start + fold_size
            train_end = test_start - self.purge_gap
            
            train_indices = np.arange(0, train_end)
            test_indices = np.arange(test_start, test_end)
            
            yield train_indices, test_indices
```

**Ù…Ù†Ø§Ø¨Ø¹:** Kaggle Best Practices, Combinatorial Purged CV

---

### 2.4 Permutation Importance (Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ÛŒÙ† Ø±ÙˆØ´)

```python
from sklearn.inspection import permutation_importance

perm_result = permutation_importance(
    model, X_val, y_val,
    n_repeats=10,
    random_state=42
)
```

**Ù…Ù†Ø§Ø¨Ø¹:** scikit-learn, Reddit ML discussions

---

## Ø¯ÙˆØ±Ù‡ Ø³ÙˆÙ…: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ

### 3.1 Path Smoothing Regularization

```python
params = {
    'path_smooth': 1.0,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overfitting
    'min_data_in_leaf': 20
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** LightGBM Parameters

---

### 3.2 Interaction Constraints

```python
params = {
    'interaction_constraints': [
        [0, 1, 2],  # technical features
        [3, 4, 5]   # price features
    ]
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #2884

---

### 3.3 Monotone Constraints

```python
monotone_constraints = []
for col in X.columns:
    if 'rsi' in col.lower():
        monotone_constraints.append(1)
    else:
        monotone_constraints.append(0)

params['monotone_constraints'] = monotone_constraints
```

**Ù…Ù†Ø§Ø¨Ø¹:** ethen8181 Blog

---

## Ø¯ÙˆØ±Ù‡ Ú†Ù‡Ø§Ø±Ù…: Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø¹Ù…ÛŒÙ‚

### 4.1 Histogram Pool Size Optimization

**ÙØ±Ù…ÙˆÙ„:**
```
RAM = num_leaves Ã— 20 Ã— num_features Ã— num_bins (bytes)
```

**Ù…Ø«Ø§Ù„:** 3885 features, 1023 leaves, 255 bins = ~20GB!

**Ø±Ø§Ù‡Ú©Ø§Ø±:**
```python
params = {
    'histogram_pool_size': 8192,  # 8GB
    'num_leaves': 255,
    'max_bin': 127
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #261, #271, LightGBM FAQ

---

### 4.2 Two-Round Loading

```python
train_data = lgb.Dataset(
    X, label=y,
    params={'two_round': True}
)
```

**ØªØ£Ø«ÛŒØ±:** Ú©Ø§Ù‡Ø´ 50% peak memory

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #1146, #1032

---

### 4.3 EFB (Exclusive Feature Bundling)

**Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø±:**
- Features Ø¨Ø§ conflict Ú©Ù… bundle Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
- Ú©Ø§Ù‡Ø´ 30-70% ØªØ¹Ø¯Ø§Ø¯ features
- Automatic (Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ù†Ø¯Ø§Ø±Ø¯)

**Ù…Ù†Ø§Ø¨Ø¹:** LightGBM NIPS Paper, GitHub #3010

---

### 4.4 Force Col-Wise vs Row-Wise

**Ø¬Ø¯ÙˆÙ„ ØªØµÙ…ÛŒÙ…:**

| Ø´Ø±Ø§ÛŒØ· | Ø§Ù†ØªØ®Ø§Ø¨ |
|-------|--------|
| #features > 1000 | col_wise |
| #threads > 20 | col_wise |
| RAM Ù…Ø­Ø¯ÙˆØ¯ | col_wise |
| #data > 1M & bins < 100 | row_wise |

**Ø¨Ø±Ø§ÛŒ 3885 ÙÛŒÚ†Ø± TSfresh:**
```python
params = {'force_col_wise': True}
```

**Ù…Ù†Ø§Ø¨Ø¹:** Parameters Documentation

---

## Ø¯ÙˆØ±Ù‡ Ù¾Ù†Ø¬Ù…: Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Data Leakage Ùˆ Overfitting

### 5.1 Ø¯Ø±Ú© Data Leakage Ø¯Ø± Time Series

**ØªØ¹Ø±ÛŒÙ:** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± Ø²Ù…Ø§Ù† prediction Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.

**Ø§Ù†ÙˆØ§Ø¹ Leakage:**

#### 5.1.1 Look-Ahead Bias (Ù†Ú¯Ø§Ù‡ Ø¨Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡)

**Ù…Ø«Ø§Ù„ Ø§Ø´ØªØ¨Ø§Ù‡:**
```python
# âŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ rolling mean Ø§Ø² Ú©Ù„ data
df['rolling_mean'] = df['close'].rolling(window=10).mean()

# Ø¨Ø¹Ø¯ split
X_train, X_test = train_test_split(df)
```

**Ù…Ø´Ú©Ù„:** rolling mean Ø¯Ø± train Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ test Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡!

**Ø±Ø§Ù‡Ú©Ø§Ø± ØµØ­ÛŒØ­:**
```python
# âœ… split Ø§ÙˆÙ„ØŒ Ø¨Ø¹Ø¯ feature engineering
train_df = df[:split_point]
test_df = df[split_point:]

train_df['rolling_mean'] = train_df['close'].rolling(10).mean()
test_df['rolling_mean'] = test_df['close'].rolling(10).mean()
```

**Ù…Ù†Ø§Ø¨Ø¹:** TrainingData Blog, Nature Scientific Reports

---

#### 5.1.2 Target Leakage (Ù†Ø´Øª target)

**Ù…Ø«Ø§Ù„ Ø§Ø´ØªØ¨Ø§Ù‡:**
```python
# âŒ target encoding Ø¨Ø§ Ú©Ù„ dataset
for cat in categorical_cols:
    df[f'{cat}_encoded'] = df.groupby(cat)['target'].transform('mean')
```

**Ù…Ø´Ú©Ù„:** target Ø¯Ø± features Ù„Ùˆ Ø±ÙØªÙ‡!

**Ø±Ø§Ù‡Ú©Ø§Ø± ØµØ­ÛŒØ­ (Leave-One-Out Encoding):**
```python
def loo_encoding(df, cat_col, target_col):
    # Ø¨Ø±Ø§ÛŒ Ù‡Ø± rowØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø¯ÙˆÙ† Ø®ÙˆØ¯ row
    global_mean = df[target_col].mean()
    
    agg = df.groupby(cat_col)[target_col].agg(['sum', 'count'])
    
    encoded = []
    for idx, row in df.iterrows():
        cat = row[cat_col]
        if agg.loc[cat, 'count'] > 1:
            # Ø­Ø°Ù Ø®ÙˆØ¯ row
            encoded.append(
                (agg.loc[cat, 'sum'] - row[target_col]) / 
                (agg.loc[cat, 'count'] - 1)
            )
        else:
            encoded.append(global_mean)
    
    return encoded
```

**ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CatBoost Ordered Target Encoding:**
```python
# CatBoost Ø¨Ù‡ ØµÙˆØ±Øª automatic Ø§Ø² ordered encoding Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# Ú©Ù‡ target leakage Ù†Ø¯Ø§Ø±Ø¯
```

**Ù…Ù†Ø§Ø¨Ø¹:** CatBoost Paper (NeurIPS 2018), WandB Feature Engineering, Neptune.ai

---

#### 5.1.3 Future Information in Rolling Features

**Ù…Ø´Ú©Ù„ TSfresh:**

TSfresh features Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§Ø² window Ú¯Ø°Ø´ØªÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŒ Ø§Ù…Ø§:

```python
# âŒ Ø§Ú¯Ø± tsfresh Ø±ÙˆÛŒ Ú©Ù„ data Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
from tsfresh import extract_features

# Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« leakage Ù…ÛŒâ€ŒØ´ÙˆØ¯!
features = extract_features(df, column_id='id', column_sort='time')
```

**Ø±Ø§Ù‡Ú©Ø§Ø± ØµØ­ÛŒØ­:**
```python
# âœ… rolling window extraction Ø¨Ø§ gap
def extract_tsfresh_with_gap(df, window_size, gap):
    """
    gap: ØªØ¹Ø¯Ø§Ø¯ samples Ú©Ù‡ Ù†Ø¨Ø§ÛŒØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯
    """
    all_features = []
    
    for i in range(window_size + gap, len(df)):
        # ÙÙ‚Ø· Ø§Ø² window Ú¯Ø°Ø´ØªÙ‡ (Ø¨Ø§ gap) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        window_end = i - gap
        window_start = max(0, window_end - window_size)
        
        window_df = df[window_start:window_end]
        features = extract_features(window_df, ...)
        all_features.append(features)
    
    return pd.concat(all_features)
```

**Ù…Ù†Ø§Ø¨Ø¹:** Reddit ML, Frontiers Research, Kaggle Time Series

---

### 5.2 STL Decomposition Leakage

**Ù…Ø´Ú©Ù„:**
```python
# âŒ STL Ø±ÙˆÛŒ Ú©Ù„ test set
from statsmodels.tsa.seasonal import STL

# Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« future leakage Ù…ÛŒâ€ŒØ´ÙˆØ¯
stl = STL(test_data, seasonal=7)
result = stl.fit()
```

**Ø±Ø§Ù‡Ú©Ø§Ø±:**
```python
# âœ… STL Ø¨Ø±Ø§ÛŒ Ù‡Ø± sample Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
def stl_decompose_per_sample(df, window_size=100):
    results = []
    
    for i in range(window_size, len(df)):
        # ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        historical = df[:i][-window_size:]
        
        stl = STL(historical, seasonal=7)
        result = stl.fit()
        
        # ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø±Ø§ Ø¨Ú¯ÛŒØ±
        results.append({
            'trend': result.trend.iloc[-1],
            'seasonal': result.seasonal.iloc[-1],
            'resid': result.resid.iloc[-1]
        })
    
    return pd.DataFrame(results)
```

**Ù…Ù†Ø§Ø¨Ø¹:** Frontiers in Environmental Science 2025, GitHub AutoGluon #2779

---

### 5.3 Lag Features Ø¨Ø§ Gap ØµØ­ÛŒØ­

**Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ fÛŒÚ†Ø±Ù‡Ø§ÛŒ TSfresh:**

Ø§Ú¯Ø± TSfresh Ø§Ø² window 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡ (Ø¨Ø±Ø§ÛŒ 15-minute data = 2 bars):

```python
def create_lag_features_with_proper_gap(df, prediction_horizon=1):
    """
    prediction_horizon: Ú†Ù†Ø¯ step Ø¬Ù„Ùˆ Ø±Ø§ predict Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    """
    
    # gap Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ = prediction_horizon
    min_gap = prediction_horizon
    
    # Ø¨Ø±Ø§ÛŒ TSfresh Ø¨Ø§ window=2 bars
    tsfresh_window = 2
    
    # gap Ú©Ù„
    total_gap = min_gap + tsfresh_window
    
    # Ø§ÛŒØ¬Ø§Ø¯ lags Ø¨Ø§ gap Ù…Ù†Ø§Ø³Ø¨
    for lag in range(total_gap, total_gap + 10):
        df[f'lag_{lag}'] = df['value'].shift(lag)
    
    return df
```

**Ù…Ù†Ø§Ø¨Ø¹:** Kaggle TS-10, Reddit Quant

---

### 5.4 Overfitting Detection Ùˆ Prevention

#### 5.4.1 Train/Valid Gap Monitoring

```python
def calculate_overfit_ratio(train_metric, valid_metric):
    """
    Ù†Ø³Ø¨Øª Ø¨ÛŒØ´â€ŒØ¨Ø±Ø§Ø²Ø´
    """
    if train_metric > 0:
        return valid_metric / train_metric
    return np.inf

def custom_early_stopping_with_overfit_check(
    stopping_rounds=50,
    overfit_tolerance=1.15
):
    """
    Stop Ø§Ú¯Ø±:
    1. valid Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÛŒØ§ÙØª
    2. overfit_ratio > tolerance
    """
    
    best_score = None
    best_iter = 0
    counter = 0
    
    def callback(env):
        nonlocal best_score, best_iter, counter
        
        if len(env.evaluation_result_list) >= 1:
            valid_score = env.evaluation_result_list[0][2]
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
            if best_score is None or valid_score > best_score:
                best_score = valid_score
                best_iter = env.iteration
                counter = 0
            else:
                counter += 1
                if counter >= stopping_rounds:
                    raise lgb.callback.EarlyStopException(
                        best_iter, best_score
                    )
    
    return callback
```

**Ù…Ù†Ø§Ø¨Ø¹:** GitHub #4996, #278

---

#### 5.4.2 Regularization Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª

**ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Ø¯Ù‚Øª > Ø³Ø±Ø¹Øª):**

```python
params = {
    # Tree Structure (Ù…Ø­Ø¯ÙˆØ¯ØªØ± Ø¨Ø±Ø§ÛŒ overfitting Ú©Ù…ØªØ±)
    'num_leaves': 31,  # Ù†Ù‡ Ø¨ÛŒØ´ØªØ±
    'max_depth': 6,  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¹Ù…Ù‚
    'min_data_in_leaf': 50,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª
    'min_gain_to_split': 0.02,  # Ø§ÙØ²Ø§ÛŒØ´
    
    # Regularization Ù‚ÙˆÛŒ
    'lambda_l1': 0.5,  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 0.1
    'lambda_l2': 0.5,  # Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø² 0.1
    'path_smooth': 2.0,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ regularization Ø¨ÛŒØ´ØªØ±
    
    # Feature/Data Sampling
    'feature_fraction': 0.8,  # Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² overfit
    'bagging_fraction': 0.7,  # Ú©Ø§Ù‡Ø´
    'bagging_freq': 5,
    
    # Categorical (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)
    'min_data_per_group': 200,  # Ø§ÙØ²Ø§ÛŒØ´
    'cat_smooth': 20.0,  # Ø§ÙØ²Ø§ÛŒØ´
    'cat_l2': 20.0,  # Ø§ÙØ²Ø§ÛŒØ´
    
    # Learning
    'learning_rate': 0.01,  # Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
    'num_iterations': 1000,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø§ early stopping
}
```

**Ù…Ù†Ø§Ø¨Ø¹:** XGBoost vs LightGBM, TowardsDataScience

---

### 5.5 Spurious Correlation Detection

**Ù…Ø´Ú©Ù„:** ÙÛŒÚ†Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± train Ø®ÙˆØ¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ù†Ø¯ Ø§Ù…Ø§ spurious Ù‡Ø³ØªÙ†Ø¯.

**ØªØ´Ø®ÛŒØµ:**

```python
def detect_spurious_features(X, y, model, n_runs=20):
    """
    ÙÛŒÚ†Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ importance Ø¢Ù†Ù‡Ø§ Ù†Ø§Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³Øª Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ spurious Ù‡Ø³ØªÙ†Ø¯
    """
    
    importances = []
    
    for seed in range(n_runs):
        # Train Ø¨Ø§ seed Ù…Ø®ØªÙ„Ù
        model.set_params(random_state=seed)
        model.fit(X, y)
        
        imp = model.feature_importance(importance_type='gain')
        importances.append(imp)
    
    importances = np.array(importances)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ coefficient of variation
    mean_imp = importances.mean(axis=0)
    std_imp = importances.std(axis=0)
    cv = std_imp / (mean_imp + 1e-10)
    
    # ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø¨Ø§ CV Ø¨Ø§Ù„Ø§ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ spurious
    spurious_threshold = 1.0  # Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…
    spurious_features = X.columns[cv > spurious_threshold].tolist()
    
    return {
        'feature': X.columns,
        'mean_importance': mean_imp,
        'std_importance': std_imp,
        'cv': cv,
        'is_spurious': cv > spurious_threshold
    }
```

**Ù…Ù†Ø§Ø¨Ø¹:** Stanford AI Lab, Nature papers on spurious features

---

### 5.6 Null Importance Test (Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ feature validation)

**ØªØ¦ÙˆØ±ÛŒ:**
- Ø§Ú¯Ø± feature ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ù‡Ù… Ø§Ø³ØªØŒ importance Ø¢Ù† Ø¨Ø§ÛŒØ¯ >> null importance Ø¨Ø§Ø´Ø¯
- Null importance = importance ÙˆÙ‚ØªÛŒ target shuffle Ø´Ø¯Ù‡ (random)

**Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµØ­ÛŒØ­:**

```python
def null_importance_test_robust(
    X, y, 
    n_actual=20,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª
    n_null=100,  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±
    cv_splits=5
):
    """
    Null importance Ø¨Ø§ cross-validation Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§
    """
    
    from sklearn.model_selection import KFold
    
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'n_estimators': 200,
        'importance_type': 'gain',  # Ø­ÛŒØ§ØªÛŒ
        'verbose': -1
    }
    
    # Actual importances (Ø¨Ø§ CV)
    actual_importances = []
    
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)
    
    for run in range(n_actual):
        fold_importances = []
        
        for train_idx, val_idx in kf.split(X):
            X_train = X.iloc[train_idx]
            y_train = y.iloc[train_idx]
            
            model = lgb.LGBMClassifier(**params, random_state=run)
            model.fit(X_train, y_train)
            
            fold_importances.append(
                model.feature_importance(importance_type='gain')
            )
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø² folds
        actual_importances.append(np.mean(fold_importances, axis=0))
    
    # Null importances
    null_importances = []
    
    for run in range(n_null):
        fold_importances = []
        
        # Shuffle target
        y_shuffled = y.sample(frac=1, random_state=run).values
        
        for train_idx, val_idx in kf.split(X):
            X_train = X.iloc[train_idx]
            y_train_shuffled = y_shuffled[train_idx]
            
            model = lgb.LGBMClassifier(**params, random_state=run)
            model.fit(X_train, y_train_shuffled)
            
            fold_importances.append(
                model.feature_importance(importance_type='gain')
            )
        
        null_importances.append(np.mean(fold_importances, axis=0))
    
    # Ø¢Ù†Ø§Ù„ÛŒØ² statistical
    actual_mean = np.mean(actual_importances, axis=0)
    actual_std = np.std(actual_importances, axis=0)
    
    null_mean = np.mean(null_importances, axis=0)
    null_std = np.std(null_importances, axis=0)
    
    # Z-score
    z_scores = (actual_mean - null_mean) / (null_std + 1e-10)
    
    # P-value (two-tailed)
    from scipy import stats
    p_values = 2 * (1 - stats.norm.cdf(np.abs(z_scores)))
    
    # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ
    significance_level = 0.05
    is_significant = p_values < significance_level
    
    # Score Ù†Ù‡Ø§ÛŒÛŒ (actual / null ratio)
    importance_ratio = actual_mean / (null_mean + 1e-10)
    
    results = pd.DataFrame({
        'feature': X.columns,
        'actual_importance_mean': actual_mean,
        'actual_importance_std': actual_std,
        'null_importance_mean': null_mean,
        'null_importance_std': null_std,
        'z_score': z_scores,
        'p_value': p_values,
        'is_significant': is_significant,
        'importance_ratio': importance_ratio
    })
    
    results = results.sort_values('z_score', ascending=False)
    
    return results
```

**ØªÙØ³ÛŒØ± Ù†ØªØ§ÛŒØ¬:**
- **z_score > 3**: ÙÛŒÚ†Ø± Ù‚Ø·Ø¹Ø§Ù‹ Ù…Ù‡Ù… Ø§Ø³Øª
- **2 < z_score < 3**: ÙÛŒÚ†Ø± Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù…Ù‡Ù… Ø§Ø³Øª
- **z_score < 2**: ÙÛŒÚ†Ø± Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ spurious ÛŒØ§ weak Ø§Ø³Øª
- **importance_ratio > 2**: ÙÛŒÚ†Ø± 2x Ø¨Ù‡ØªØ± Ø§Ø² random Ø§Ø³Øª

**Ù…Ù†Ø§Ø¨Ø¹:** Kaggle Feature Selection, IEEE Papers, Reddit ML

---

### 5.7 Cross-Validated Permutation Importance

**Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ stability:**

```python
def cv_permutation_importance(
    X, y,
    n_repeats=10,
    cv_splits=5
):
    """
    Permutation importance Ø¨Ø§ cross-validation
    """
    
    from sklearn.inspection import permutation_importance
    from sklearn.model_selection import KFold
    
    all_importances = []
    
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)
    
    for fold_num, (train_idx, val_idx) in enumerate(kf.split(X)):
        print(f"Fold {fold_num + 1}/{cv_splits}")
        
        X_train = X.iloc[train_idx]
        X_val = X.iloc[val_idx]
        y_train = y.iloc[train_idx]
        y_val = y.iloc[val_idx]
        
        # Train model
        model = lgb.LGBMClassifier(
            n_estimators=200,
            learning_rate=0.05,
            num_leaves=31,
            random_state=42
        )
        model.fit(X_train, y_train)
        
        # Permutation importance
        perm_result = permutation_importance(
            model, X_val, y_val,
            n_repeats=n_repeats,
            random_state=42,
            n_jobs=-1
        )
        
        all_importances.append(perm_result.importances_mean)
    
    # Aggregate Ø§Ø² Ù‡Ù…Ù‡ folds
    mean_importance = np.mean(all_importances, axis=0)
    std_importance = np.std(all_importances, axis=0)
    
    results = pd.DataFrame({
        'feature': X.columns,
        'importance_mean': mean_importance,
        'importance_std': std_importance,
        'cv_coefficient': std_importance / (mean_importance + 1e-10)
    })
    
    results = results.sort_values('importance_mean', ascending=False)
    
    return results
```

**Ù…Ù†Ø§Ø¨Ø¹:** scikit-learn, Reddit ML

---

### 5.8 Combined Feature Selection Strategy (Ù†Ù‡Ø§ÛŒÛŒ)

**Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ multi-stage Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª maximum:**

```python
class AccuracyFirstFeatureSelector:
    """
    Feature selection Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¯Ù‚Øª
    """
    
    def __init__(self, significance_level=0.05):
        self.significance_level = significance_level
    
    def select_features(self, X, y):
        """
        Ù…Ø±Ø§Ø­Ù„:
        1. Null importance test
        2. Permutation importance (CV)
        3. Feature stability
        4. Spurious correlation detection
        5. Final ranking
        """
        
        print("Step 1/5: Null Importance Test...")
        null_results = self.null_importance_test_robust(
            X, y, n_actual=20, n_null=100
        )
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† insignificant features
        significant_features = null_results[
            null_results['is_significant']
        ]['feature'].tolist()
        
        print(f"  Significant features: {len(significant_features)}/{len(X.columns)}")
        
        X_filtered = X[significant_features]
        
        print("\nStep 2/5: Permutation Importance...")
        perm_results = self.cv_permutation_importance(
            X_filtered, y, n_repeats=10, cv_splits=5
        )
        
        print("\nStep 3/5: Feature Stability Test...")
        stability_results = self.detect_spurious_features(
            X_filtered, y, n_runs=20
        )
        
        print("\nStep 4/5: Combining Results...")
        
        # Merge Ù‡Ù…Ù‡ Ù†ØªØ§ÛŒØ¬
        final_results = null_results[
            null_results['feature'].isin(significant_features)
        ].copy()
        
        final_results = final_results.merge(
            perm_results[['feature', 'importance_mean', 'cv_coefficient']],
            on='feature',
            suffixes=('_null', '_perm')
        )
        
        final_results = final_results.merge(
            stability_results[['feature', 'cv']],
            on='feature'
        )
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ combined score
        # ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ: 40% null importance, 40% permutation, 20% stability
        
        # Normalize Ù‡Ø± metric
        final_results['null_score_norm'] = (
            final_results['z_score'] / final_results['z_score'].max()
        )
        
        final_results['perm_score_norm'] = (
            final_results['importance_mean'] / 
            final_results['importance_mean'].max()
        )
        
        final_results['stability_score_norm'] = (
            1 - (final_results['cv'] / final_results['cv'].max())
        )
        
        # Combined score
        final_results['final_score'] = (
            0.4 * final_results['null_score_norm'] +
            0.4 * final_results['perm_score_norm'] +
            0.2 * final_results['stability_score_norm']
        )
        
        final_results = final_results.sort_values(
            'final_score', ascending=False
        )
        
        print("\nStep 5/5: Final Ranking Complete")
        print(f"Total features evaluated: {len(X.columns)}")
        print(f"Significant features: {len(final_results)}")
        
        return final_results
```

**Ù…Ù†Ø§Ø¨Ø¹:** Integration of multiple sources

---

## Ú©Ø¯ Ù†Ù‡Ø§ÛŒÛŒ Production-Grade

```python
"""
Production-Ready Feature Selector
Ø§ÙˆÙ„ÙˆÛŒØª: Ø¯Ù‚Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± >> Ø³Ø±Ø¹Øª Ùˆ Ø­Ø§ÙØ¸Ù‡
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
import psutil
import os
from sklearn.model_selection import KFold, train_test_split
from sklearn.inspection import permutation_importance
from scipy import stats
import logging
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CPU
physical_cores = psutil.cpu_count(logical=False)
os.environ['OMP_NUM_THREADS'] = str(physical_cores)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class PurgedTimeSeriesSplit:
    """
    Time series split Ø¨Ø§ purging Ùˆ embargo
    """
    def __init__(self, n_splits=5, purge_gap=50, embargo_gap=20):
        self.n_splits = n_splits
        self.purge_gap = purge_gap
        self.embargo_gap = embargo_gap
    
    def split(self, X, y=None, groups=None):
        n_samples = len(X)
        fold_size = n_samples // (self.n_splits + 1)
        
        for i in range(self.n_splits):
            test_start = (i + 1) * fold_size
            test_end = min(test_start + fold_size, n_samples)
            
            train_end = test_start - self.purge_gap
            train_start = 0
            
            train_indices = np.arange(train_start, train_end)
            test_indices = np.arange(test_start, test_end)
            
            if len(train_indices) > 0 and len(test_indices) > 0:
                yield train_indices, test_indices


class AccuracyFirstFeatureSelector:
    """
    Feature Selector Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø¯Ù‚Øª Ùˆ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² leakage
    """
    
    def __init__(
        self,
        target_column='target',
        classification=True,
        significance_level=0.05,
        random_state=42
    ):
        self.target_column = target_column
        self.classification = classification
        self.significance_level = significance_level
        self.random_state = random_state
        self.physical_cores = physical_cores
    
    def _get_conservative_params(self):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø±Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§
        """
        return {
            'objective': 'binary' if self.classification else 'regression',
            'metric': 'auc' if self.classification else 'rmse',
            'boosting_type': 'gbdt',
            
            # CPU
            'num_threads': self.physical_cores,
            'force_col_wise': True,
            'deterministic': True,
            
            # Tree - Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø±Ø§ÛŒ overfitting Ú©Ù…ØªØ±
            'num_leaves': 31,
            'max_depth': 6,
            'min_data_in_leaf': 50,
            'min_gain_to_split': 0.02,
            
            # Regularization - Ù‚ÙˆÛŒ
            'lambda_l1': 0.5,
            'lambda_l2': 0.5,
            'path_smooth': 2.0,
            
            # Sampling
            'feature_fraction': 0.8,
            'bagging_fraction': 0.7,
            'bagging_freq': 5,
            
            # Categorical
            'min_data_per_group': 200,
            'cat_smooth': 20.0,
            'cat_l2': 20.0,
            
            # Learning
            'learning_rate': 0.01,
            'n_estimators': 1000,
            
            # Other
            'verbose': -1,
            'random_state': self.random_state
        }
    
    def null_importance_test(
        self,
        X, y,
        n_actual=20,
        n_null=100,
        cv_splits=5
    ):
        """
        Null importance test Ø¨Ø§ CV
        """
        logging.info(f"Null Importance: {n_actual} actual, {n_null} null, {cv_splits} CV")
        
        params = self._get_conservative_params()
        params['n_estimators'] = 200  # Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¯Ø± null test
        
        # Actual
        actual_importances = []
        kf = KFold(n_splits=cv_splits, shuffle=True, random_state=self.random_state)
        
        for run in range(n_actual):
            fold_importances = []
            
            for train_idx, val_idx in kf.split(X):
                X_train = X.iloc[train_idx]
                y_train = y.iloc[train_idx]
                
                model = lgb.LGBMClassifier(**params)
                model.set_params(random_state=run)
                model.fit(X_train, y_train, verbose=False)
                
                fold_importances.append(
                    model.feature_importance(importance_type='gain')
                )
            
            actual_importances.append(np.mean(fold_importances, axis=0))
            
            if (run + 1) % 5 == 0:
                logging.info(f"  Actual runs: {run + 1}/{n_actual}")
        
        # Null
        null_importances = []
        
        for run in range(n_null):
            fold_importances = []
            
            y_shuffled = y.sample(frac=1, random_state=run).values
            
            for train_idx, val_idx in kf.split(X):
                X_train = X.iloc[train_idx]
                y_train_shuffled = y_shuffled[train_idx]
                
                model = lgb.LGBMClassifier(**params)
                model.set_params(random_state=run)
                model.fit(X_train, y_train_shuffled, verbose=False)
                
                fold_importances.append(
                    model.feature_importance(importance_type='gain')
                )
            
            null_importances.append(np.mean(fold_importances, axis=0))
            
            if (run + 1) % 20 == 0:
                logging.info(f"  Null runs: {run + 1}/{n_null}")
        
        # Statistics
        actual_mean = np.mean(actual_importances, axis=0)
        null_mean = np.mean(null_importances, axis=0)
        null_std = np.std(null_importances, axis=0)
        
        z_scores = (actual_mean - null_mean) / (null_std + 1e-10)
        p_values = 2 * (1 - stats.norm.cdf(np.abs(z_scores)))
        
        is_significant = p_values < self.significance_level
        
        results = pd.DataFrame({
            'feature': X.columns,
            'actual_importance': actual_mean,
            'null_importance': null_mean,
            'z_score': z_scores,
            'p_value': p_values,
            'is_significant': is_significant
        })
        
        return results
    
    def permutation_importance_cv(
        self,
        X, y,
        n_repeats=10,
        cv_splits=5
    ):
        """
        Permutation importance Ø¨Ø§ CV
        """
        logging.info(f"Permutation Importance: {n_repeats} repeats, {cv_splits} CV")
        
        params = self._get_conservative_params()
        params['n_estimators'] = 300
        
        all_importances = []
        
        kf = KFold(n_splits=cv_splits, shuffle=True, random_state=self.random_state)
        
        for fold_num, (train_idx, val_idx) in enumerate(kf.split(X)):
            logging.info(f"  Fold {fold_num + 1}/{cv_splits}")
            
            X_train = X.iloc[train_idx]
            X_val = X.iloc[val_idx]
            y_train = y.iloc[train_idx]
            y_val = y.iloc[val_idx]
            
            model = lgb.LGBMClassifier(**params)
            model.fit(X_train, y_train, verbose=False)
            
            perm_result = permutation_importance(
                model, X_val, y_val,
                n_repeats=n_repeats,
                random_state=self.random_state,
                n_jobs=self.physical_cores
            )
            
            all_importances.append(perm_result.importances_mean)
        
        mean_importance = np.mean(all_importances, axis=0)
        std_importance = np.std(all_importances, axis=0)
        
        results = pd.DataFrame({
            'feature': X.columns,
            'perm_importance': mean_importance,
            'perm_std': std_importance
        })
        
        return results
    
    def feature_stability_test(
        self,
        X, y,
        n_runs=20
    ):
        """
        Feature stability test
        """
        logging.info(f"Feature Stability: {n_runs} runs")
        
        params = self._get_conservative_params()
        params['n_estimators'] = 200
        
        all_importances = []
        
        for run in range(n_runs):
            model = lgb.LGBMClassifier(**params)
            model.set_params(random_state=run)
            model.fit(X, y, verbose=False)
            
            all_importances.append(
                model.feature_importance(importance_type='gain')
            )
            
            if (run + 1) % 5 == 0:
                logging.info(f"  Run {run + 1}/{n_runs}")
        
        mean_imp = np.mean(all_importances, axis=0)
        std_imp = np.std(all_importances, axis=0)
        cv_scores = std_imp / (mean_imp + 1e-10)
        
        results = pd.DataFrame({
            'feature': X.columns,
            'stability_cv': cv_scores
        })
        
        return results
    
    def select_features(self, X, y):
        """
        Pipeline Ú©Ø§Ù…Ù„ feature selection
        """
        logging.info("="*50)
        logging.info("Feature Selection Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¯Ù‚Øª")
        logging.info(f"Total features: {len(X.columns)}")
        logging.info("="*50)
        
        # 1. Null Importance
        logging.info("\n[1/3] Null Importance Test")
        null_results = self.null_importance_test(
            X, y,
            n_actual=20,
            n_null=100,
            cv_splits=5
        )
        
        significant_features = null_results[
            null_results['is_significant']
        ]['feature'].tolist()
        
        logging.info(f"Significant features: {len(significant_features)}/{len(X.columns)}")
        
        if len(significant_features) == 0:
            logging.warning("Ù‡ÛŒÚ† feature Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
            return null_results
        
        X_filtered = X[significant_features]
        
        # 2. Permutation Importance
        logging.info("\n[2/3] Permutation Importance")
        perm_results = self.permutation_importance_cv(
            X_filtered, y,
            n_repeats=10,
            cv_splits=5
        )
        
        # 3. Stability
        logging.info("\n[3/3] Feature Stability")
        stability_results = self.feature_stability_test(
            X_filtered, y,
            n_runs=20
        )
        
        # Combine
        logging.info("\nCombining results...")
        
        final_results = null_results[
            null_results['feature'].isin(significant_features)
        ].copy()
        
        final_results = final_results.merge(
            perm_results, on='feature'
        )
        
        final_results = final_results.merge(
            stability_results, on='feature'
        )
        
        # Normalize Ùˆ combine
        final_results['null_score_norm'] = (
            final_results['z_score'] / final_results['z_score'].max()
        )
        
        final_results['perm_score_norm'] = (
            final_results['perm_importance'] / 
            final_results['perm_importance'].max()
        )
        
        final_results['stability_score_norm'] = (
            1 - (final_results['stability_cv'] / 
                 final_results['stability_cv'].max())
        )
        
        # Combined: 40% null, 40% perm, 20% stability
        final_results['final_score'] = (
            0.4 * final_results['null_score_norm'] +
            0.4 * final_results['perm_score_norm'] +
            0.2 * final_results['stability_score_norm']
        )
        
        final_results = final_results.sort_values(
            'final_score', ascending=False
        )
        
        logging.info("\n" + "="*50)
        logging.info("Feature Selection Complete!")
        logging.info(f"Selected: {len(final_results)} features")
        logging.info("="*50)
        
        return final_results


# Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ data
    df = pd.read_csv('your_tsfresh_features.csv')
    
    # Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† features Ùˆ target
    feature_cols = [c for c in df.columns if c != 'target']
    X = df[feature_cols]
    y = df['target']
    
    # Feature selection
    selector = AccuracyFirstFeatureSelector(
        target_column='target',
        classification=True,
        significance_level=0.05
    )
    
    results = selector.select_features(X, y)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    results.to_csv('feature_selection_results.csv', index=False)
    
    # Ù†Ù…Ø§ÛŒØ´ top 50
    print("\nTop 50 Features:")
    print(results.head(50))
    
    # Ø¢Ù…Ø§Ø±
    print("\nStatistics:")
    print(f"Total evaluated: {len(X.columns)}")
    print(f"Significant: {len(results)}")
    print(f"With final_score > 0.7: {len(results[results['final_score'] > 0.7])}")
```

---

## Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ú©Ø§Ù…Ù„ Production

### âœ… Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Data Leakage

- [ ] Split Ù‚Ø¨Ù„ Ø§Ø² feature engineering
- [ ] Rolling features Ø¨Ø§ gap Ù…Ù†Ø§Ø³Ø¨
- [ ] STL decomposition per sample
- [ ] Target encoding Ø¨Ø§ leave-one-out
- [ ] Purged time series split Ø¨Ø§ embargo
- [ ] Gap Ø¨ÛŒÙ† train Ùˆ test
- [ ] Ù‡ÛŒÚ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢ÛŒÙ†Ø¯Ù‡ Ø¯Ø± features

### âœ… Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting

- [ ] Regularization Ù‚ÙˆÛŒ (L1, L2, path_smooth)
- [ ] Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† tree depth
- [ ] Ø§ÙØ²Ø§ÛŒØ´ min_data_in_leaf
- [ ] Feature/data sampling
- [ ] Early stopping Ø¨Ø§ overfit monitoring
- [ ] Cross-validation Ø¨Ø§ 5+ folds

### âœ… Feature Importance

- [ ] Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 'gain' Ù†Ù‡ 'split'
- [ ] Null importance test (n_null >= 100)
- [ ] Permutation importance Ø¨Ø§ CV
- [ ] Feature stability testing
- [ ] Combined scoring

### âœ… Validation Strategy

- [ ] Purged time series split
- [ ] ÙÙ‚Ø· validation Ø¯Ø± valid_sets
- [ ] Stratified=False Ø¨Ø±Ø§ÛŒ time series
- [ ] Gap Ùˆ embargo Ù…Ù†Ø§Ø³Ø¨

### âœ… LightGBM Configuration

- [ ] `boosting_type='gbdt'`
- [ ] `data_sample_strategy='goss'` (Ø§Ú¯Ø± data Ø¨Ø²Ø±Ú¯)
- [ ] `force_col_wise=True` (Ø¨Ø±Ø§ÛŒ features Ø²ÛŒØ§Ø¯)
- [ ] `num_threads=physical_cores`
- [ ] `deterministic=True`

### âœ… Ø¯Ù‚Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±

- [ ] n_actual >= 20 Ø¯Ø± null importance
- [ ] n_null >= 100 Ø¯Ø± null importance
- [ ] cv_splits >= 5
- [ ] n_repeats >= 10 Ø¯Ø± permutation
- [ ] Significance level = 0.05

---

## Ø®Ù„Ø§ØµÙ‡ ØªØ£Ø«ÛŒØ±Ø§Øª

### ØªØ£Ø«ÛŒØ± Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ (Ø§Ø¬Ø¨Ø§Ø±ÛŒ):

1. âœ… **Purged Time Series Split** - Ø­Ø°Ù data leakage
2. âœ… **Feature Importance = 'gain'** - Ø¯Ù‚Øª 30-50% Ø¨Ù‡ØªØ±
3. âœ… **Null Importance Test** - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ spurious features
4. âœ… **Split Ù‚Ø¨Ù„ Ø§Ø² feature engineering** - Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² look-ahead bias

### ØªØ£Ø«ÛŒØ± Ø¨Ø§Ù„Ø§ (Ø¨Ø³ÛŒØ§Ø± ØªÙˆØµÛŒÙ‡):

5. âœ… **Permutation Importance + CV** - stable ranking
6. âœ… **Regularization Ù‚ÙˆÛŒ** - Ú©Ø§Ù‡Ø´ overfitting
7. âœ… **Feature Stability Testing** - Ø­Ø°Ù unstable features
8. âœ… **lgb.cv native** - efficient CV

### ØªØ£Ø«ÛŒØ± Ù…ØªÙˆØ³Ø· (Ù…ÙÛŒØ¯):

9. âœ… **Path smoothing** - regularization Ø§Ø¶Ø§ÙÛŒ
10. âœ… **Interaction/Monotone constraints** - interpretability

---

## Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø§Ù…Ø¹

### Papers Ùˆ Research:
1. CatBoost Paper (NeurIPS 2018) - Ordered boosting, target leakage
2. LightGBM Paper (NIPS 2017) - EFB, histogram-based
3. Nature Scientific Reports (2025) - Data leakage in time series
4. Frontiers Environmental Science (2025) - STL leakage
5. Stanford AI Lab - Spurious features

### Documentation:
1. LightGBM 4.6.0+ Official Docs
2. Parameters Tuning Guide
3. Advanced Topics
4. Python API Reference

### GitHub:
1. microsoft/LightGBM Issues: #512, #4425, #82, #84, #113, #2884
2. AutoGluon #2779 - Stack information leakage

### Blogs Ùˆ Tutorials:
1. WandB Feature Engineering
2. Neptune.ai - CatBoost vs others
3. TowardsDataScience - Overfitting prevention
4. TrainingData Blog - Look-ahead bias
5. Kaggle Competitions - Time series validation

---

## Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø§ Ù‡Ø¯Ù **Ø¯Ù‚Øª maximum** Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªÙ…Ø§Ù… ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø¨Ø§ ÛŒÚ©Ø¯ÛŒÚ¯Ø± integrate Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.

**Ø§ØµÙ„ Ø§Ø³Ø§Ø³ÛŒ:**
```
Ø§Ø´ØªØ¨Ø§Ù‡ Ø¯Ø± feature selection = ÙØ§Ø¬Ø¹Ù‡ Ø¯Ø± production
Ø¯Ù‚Øª Ùˆ Ø§Ø¹ØªØ¨Ø§Ø± > Ù‡Ù…Ù‡ Ú†ÛŒØ²
```

**Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:**
1. Ù‡ÛŒÚ†Ú¯Ø§Ù‡ Ø³Ø±Ø¹Øª Ø±Ø§ Ø¨Ø± Ø¯Ù‚Øª ØªØ±Ø¬ÛŒØ­ Ù†Ø¯Ù‡ÛŒØ¯ Ø¯Ø± feature selection
2. Data leakage Ø±Ø§ Ø¬Ø¯ÛŒ Ø¨Ú¯ÛŒØ±ÛŒØ¯ - Ø¨Ø³ÛŒØ§Ø± Ø±Ø§ÛŒØ¬ Ø§Ø³Øª
3. Null importance Ùˆ permutation importance Ø±Ø§ ØªØ±Ú©ÛŒØ¨ Ú©Ù†ÛŒØ¯
4. Ø§Ø² CV Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ 5 folds Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
5. Regularization Ø±Ø§ Ù‚ÙˆÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯

Ø¨Ø§ Ø±Ø¹Ø§ÛŒØª Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ØŒ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø´Ù…Ø§ Ù‚Ø¯Ø±Øª **Ø°Ø§ØªÛŒ ÙˆØ§Ù‚Ø¹ÛŒ** Ø®ÙˆØ¯ Ø±Ø§ Ù†Ø´Ø§Ù† Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø¯Ø§Ø¯ØŒ Ù†Ù‡ Ù‚Ø¯Ø±Øª Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø² data leakage ÛŒØ§ overfitting.

**Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯! ğŸ¯**
